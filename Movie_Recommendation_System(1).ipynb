{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHmWwQfJoC8c"
      },
      "source": [
        "# **Movie Recommendation System**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMklyx9boDLp"
      },
      "source": [
        "## **1. Business Objective**\n",
        "\n",
        "All entertainment websites or online stores have millions/billions of items. It becomes challenging for the customer to select the right one. At this place, recommender systems come into the picture and help the user to find the right item by minimizing the options.\n",
        "\n",
        "Recommendation Systems in the world of machine learning have become very popular and are a huge advantage to tech giants like Netflix, Amazon and many more to target their content to a specific audience. These recommendation engines are so strong in their predictions that they can dynamically alter the state of what the user sees on their page based on the user’s interaction with the app.\n",
        "\n",
        "The business objective for us is:\n",
        "1. To create a Collaborative Filtering based Movie Recommendation System.\n",
        "2. Predict the rating that a user would give to a movie that he has not yet rated.\n",
        "3. Minimize the difference between predicted and actual rating (RMSE and MAPE).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pXuBHOOoEpp"
      },
      "source": [
        "## **2. Data Collection**\n",
        "\n",
        "The dataset has been obtained from Grouplens.\n",
        "\n",
        "Link : https://grouplens.org/datasets/movielens/20m/\n",
        "\n",
        "This dataset (ml-20m) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 20000263 ratings and 465564 tag applications across 27278 movies. These data were created by 138493 users between January 09, 1995 and March 31, 2015. This dataset was generated on October 17, 2016.\n",
        "\n",
        "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
        "\n",
        "The data are contained in the files genome-scores.csv, genome-tags.csv, links.csv, movies.csv, ratings.csv and tags.csv.\n",
        "\n",
        "For our objective, we would be using \"ratings.csv\" and \"movies.csv\" data files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59d_tqVu4xsH"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feh_60uM5Fot"
      },
      "outputs": [],
      "source": [
        "# Setting up some parameters for the workbook\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams[\"figure.figsize\"] = (25,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQCU54OoU5NW",
        "outputId": "35d3d145-c3ee-48ec-c975-ba23294eacec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XANhhXia5Fus"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from surprise import Reader, Dataset\n",
        "from surprise import BaselineOnly\n",
        "from surprise import KNNBaseline\n",
        "from surprise import SlopeOne\n",
        "from surprise import SVD\n",
        "from surprise import SVDpp\n",
        "from surprise.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BECPwpDC5F07"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZJygJn3oiyv"
      },
      "source": [
        "## **3. Data Preparation/Preprocessing**\n",
        "\n",
        "We will start with loading and familiarizing with the dataset so that we can prepare the data for Machine Learning (ML) modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoeyhQQEosRr"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "movie_ratings = pd.read_csv(\"/content/ratings.csv\")\n",
        "movies = pd.read_csv(\"/content/movies.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings.head()\n"
      ],
      "metadata": {
        "id": "aFZUXj4nmQE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9f713b35-5c59-404a-eedd-deafe2e4c151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1        2     3.5  1112486027\n",
              "1       1       29     3.5  1112484676\n",
              "2       1       32     3.5  1112484819\n",
              "3       1       47     3.5  1112484727\n",
              "4       1       50     3.5  1112484580"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c1fc946-ffc9-4a10-b2a2-f6e3f88ad8e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112486027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c1fc946-ffc9-4a10-b2a2-f6e3f88ad8e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c1fc946-ffc9-4a10-b2a2-f6e3f88ad8e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c1fc946-ffc9-4a10-b2a2-f6e3f88ad8e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea53a5ea-011c-480d-8229-92e2fff8eb0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea53a5ea-011c-480d-8229-92e2fff8eb0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea53a5ea-011c-480d-8229-92e2fff8eb0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_ratings",
              "summary": "{\n  \"name\": \"movie_ratings\",\n  \"rows\": 43578,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 94,\n        \"min\": 1,\n        \"max\": 337,\n        \"num_unique_values\": 337,\n        \"samples\": [\n          47,\n          164,\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17955,\n        \"min\": 1,\n        \"max\": 128488,\n        \"num_unique_values\": 5925,\n        \"samples\": [\n          3041,\n          7034,\n          86347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0637230046921173,\n        \"min\": 0.5,\n        \"max\": 5.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5,\n          4.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 167784478,\n        \"min\": 130,\n        \"max\": 1427696465,\n        \"num_unique_values\": 31563,\n        \"samples\": [\n          1197063488,\n          845962562,\n          1329933419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies.head()"
      ],
      "metadata": {
        "id": "c3mgVx1QmhgF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e4b81b27-172a-409f-ae5e-cd38eba7e455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                               title  \\\n",
              "0        1                    Toy Story (1995)   \n",
              "1        2                      Jumanji (1995)   \n",
              "2        3             Grumpier Old Men (1995)   \n",
              "3        4            Waiting to Exhale (1995)   \n",
              "4        5  Father of the Bride Part II (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                   Adventure|Children|Fantasy  \n",
              "2                               Comedy|Romance  \n",
              "3                         Comedy|Drama|Romance  \n",
              "4                                       Comedy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80df91a8-b9ff-4598-a439-8695271c9abe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80df91a8-b9ff-4598-a439-8695271c9abe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80df91a8-b9ff-4598-a439-8695271c9abe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80df91a8-b9ff-4598-a439-8695271c9abe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bdc3b124-0006-4207-a1a8-e32df5d363bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdc3b124-0006-4207-a1a8-e32df5d363bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bdc3b124-0006-4207-a1a8-e32df5d363bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movies",
              "summary": "{\n  \"name\": \"movies\",\n  \"rows\": 20517,\n  \"fields\": [\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36003,\n        \"min\": 1,\n        \"max\": 100469,\n        \"num_unique_values\": 20517,\n        \"samples\": [\n          1543,\n          25945,\n          7644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20510,\n        \"samples\": [\n          \"Reunion (1989)\",\n          \"Last House on the Left, The (1972)\",\n          \"Last Exit to Brooklyn (1989)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1187,\n        \"samples\": [\n          \"Comedy|Crime|Drama|Romance|Thriller\",\n          \"Animation|Documentary|Drama|War\",\n          \"Action|Adventure|Animation|Children|Comedy|Sci-Fi|IMAX\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPj1K_MgDv-S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "39942d3a-f40e-40e0-a577-9aa2e6ea1dc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       userId  movieId  rating  timestamp\n",
              "0       False    False   False      False\n",
              "1       False    False   False      False\n",
              "2       False    False   False      False\n",
              "3       False    False   False      False\n",
              "4       False    False   False      False\n",
              "...       ...      ...     ...        ...\n",
              "43573   False    False   False      False\n",
              "43574   False    False   False      False\n",
              "43575   False    False   False      False\n",
              "43576   False    False   False      False\n",
              "43577   False    False   False      False\n",
              "\n",
              "[43578 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5e8696e-12a7-4257-8eaf-77b0ed3dbb6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43573</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43574</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43575</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43576</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43577</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43578 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5e8696e-12a7-4257-8eaf-77b0ed3dbb6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5e8696e-12a7-4257-8eaf-77b0ed3dbb6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5e8696e-12a7-4257-8eaf-77b0ed3dbb6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f3c43f0-4d8f-45bc-b42a-f7310edef39b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f3c43f0-4d8f-45bc-b42a-f7310edef39b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f3c43f0-4d8f-45bc-b42a-f7310edef39b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"movie_ratings\",\n  \"rows\": 43578,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Creating a newId for every movie to reduce the range of existing movieId\n",
        "#this only gives us the unique values for movies.\n",
        "movies[\"newId\"] = range(1, movies[\"movieId\"].nunique()+1)\n",
        "movies.head()\n",
        "movie_ratings.isnull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu3vydusDuhZ"
      },
      "outputs": [],
      "source": [
        "# Converting the the UTC timestamp to Datetime\n",
        "movie_ratings[\"timestamp\"] = movie_ratings[\"timestamp\"].apply(lambda x: datetime.utcfromtimestamp(x).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "# Merging the movies and ratings data files\n",
        "movie_ratings = movie_ratings.merge(movies, how=\"left\", on=\"movieId\")\n",
        "\n",
        "# Renaming the timestamp to date\n",
        "movie_ratings.rename(columns={\"timestamp\": \"date\"}, inplace=True)\n",
        "\n",
        "# Updating the movieId with the newId\n",
        "movie_ratings[\"movieId\"] = movie_ratings[\"newId\"]\n",
        "movies[\"movieId\"] = movies[\"newId\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdHjouXUIB8H"
      },
      "outputs": [],
      "source": [
        "# Dropping the newId from the datasets\n",
        "movie_ratings.drop([\"newId\"], axis=1, inplace=True)\n",
        "movies.drop([\"newId\"], axis=1, inplace=True)\n",
        "\n",
        "# Sorting ratings based on date\n",
        "movie_ratings.sort_values(by = \"date\", inplace = True)\n",
        "movie_ratings.reset_index(drop=True, inplace=True)\n",
        "#reset index basically resets the indices of the data frame and gives it a default index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxpAjFq85m3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "e719776c-b618-42a2-8321-716bc5a25458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of records are :  43578\n",
            "The number of features are :  6\n",
            "The list of features is :  Index(['userId', 'movieId', 'rating', 'date', 'title', 'genres'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating        date                             title  \\\n",
              "0     337    377.0     4.0  1970-01-01                  True Lies (1994)   \n",
              "1     172    294.0     3.0  1996-04-23               Pulp Fiction (1994)   \n",
              "2     172    298.0     3.0  1996-04-23                  Quiz Show (1994)   \n",
              "3     172    314.0     4.0  1996-04-23                   Stargate (1994)   \n",
              "4     172    316.0     5.0  1996-04-23  Shawshank Redemption, The (1994)   \n",
              "\n",
              "                                     genres  \n",
              "0  Action|Adventure|Comedy|Romance|Thriller  \n",
              "1               Comedy|Crime|Drama|Thriller  \n",
              "2                                     Drama  \n",
              "3                   Action|Adventure|Sci-Fi  \n",
              "4                               Crime|Drama  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25b927a6-d613-483b-b317-ec5ba27a990c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337</td>\n",
              "      <td>377.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1970-01-01</td>\n",
              "      <td>True Lies (1994)</td>\n",
              "      <td>Action|Adventure|Comedy|Romance|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>172</td>\n",
              "      <td>294.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1996-04-23</td>\n",
              "      <td>Pulp Fiction (1994)</td>\n",
              "      <td>Comedy|Crime|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>172</td>\n",
              "      <td>298.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1996-04-23</td>\n",
              "      <td>Quiz Show (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>172</td>\n",
              "      <td>314.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1996-04-23</td>\n",
              "      <td>Stargate (1994)</td>\n",
              "      <td>Action|Adventure|Sci-Fi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>172</td>\n",
              "      <td>316.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1996-04-23</td>\n",
              "      <td>Shawshank Redemption, The (1994)</td>\n",
              "      <td>Crime|Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25b927a6-d613-483b-b317-ec5ba27a990c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25b927a6-d613-483b-b317-ec5ba27a990c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25b927a6-d613-483b-b317-ec5ba27a990c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf41d297-c644-4d73-b131-4068865ae757\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf41d297-c644-4d73-b131-4068865ae757')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf41d297-c644-4d73-b131-4068865ae757 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_ratings",
              "summary": "{\n  \"name\": \"movie_ratings\",\n  \"rows\": 43578,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 94,\n        \"min\": 1,\n        \"max\": 337,\n        \"num_unique_values\": 337,\n        \"samples\": [\n          292,\n          177,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3607.0346408427517,\n        \"min\": 1.0,\n        \"max\": 20506.0,\n        \"num_unique_values\": 5816,\n        \"samples\": [\n          768.0,\n          5126.0,\n          10459.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.063723004692178,\n        \"min\": 0.5,\n        \"max\": 5.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.5,\n          3.0,\n          4.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          \"2008-10-22\",\n          \"2006-04-07\",\n          \"2013-01-27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5815,\n        \"samples\": [\n          \"Independence Day (a.k.a. ID4) (1996)\",\n          \"Kissing Jessica Stein (2001)\",\n          \"Kiss Kiss Bang Bang (2005)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 728,\n        \"samples\": [\n          \"Drama|Musical|Romance\",\n          \"Action|Adventure|Thriller|War\",\n          \"Animation|Comedy|Musical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Checking the features and no. of records in the dataset\n",
        "\n",
        "print(\"The number of records are : \", movie_ratings.shape[0])\n",
        "print(\"The number of features are : \", movie_ratings.shape[1])\n",
        "print(\"The list of features is : \", movie_ratings.columns)\n",
        "movie_ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AuBVm-bMkyA"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. There are about 20+M records of the data.\n",
        "2. There are 6 features: userId, movieId, rating, date, title and genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWrEBqC7M_sj"
      },
      "source": [
        "### **3.1 Data Cleaning**\n",
        "\n",
        "We will begin with data cleaning such that we can handle missing values, outliers, rare values and drop the unnecessary features that do not carry useful information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJDLOxeu-j8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdc223f-f8c8-4578-9966-742c802a5aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of duplicates records in the dataset :  0\n"
          ]
        }
      ],
      "source": [
        "# Checking for duplicates\n",
        "\n",
        "print(\"No. of duplicates records in the dataset : \", movie_ratings.columns.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEsm51F7N8BN"
      },
      "source": [
        "Observations:\n",
        "1. There are no duplicate records in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQHakfwPND5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccee38f2-c83f-4865-8066-5b84a2a9091c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43578 entries, 0 to 43577\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   userId   43578 non-null  int64  \n",
            " 1   movieId  43366 non-null  float64\n",
            " 2   rating   43578 non-null  float64\n",
            " 3   date     43578 non-null  object \n",
            " 4   title    43366 non-null  object \n",
            " 5   genres   43366 non-null  object \n",
            "dtypes: float64(2), int64(1), object(3)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# Checking the columns' titles and datatypes\n",
        "\n",
        "movie_ratings.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-pi8pklOP5C"
      },
      "source": [
        "#### **3.1.1 Handling Missing Values**\n",
        "\n",
        "Identifying the features that have some missing values and imputing them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lL_GiN0OFjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "18a2458b-883e-4f26-974a-273d8e1da9ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId       0\n",
              "movieId    212\n",
              "rating       0\n",
              "date         0\n",
              "title      212\n",
              "genres     212\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieId</th>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genres</th>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Checking the number of missing values in data\n",
        "\n",
        "movie_ratings.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYDOEv7uOtDl"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. It looks like that the dataset is well maintained as we do not see any missing values, which is good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGNdRpgMO8Tx"
      },
      "source": [
        "### **3.2 Exploratory Data Analysis**\n",
        "\n",
        "After the data cleaning steps, we can now perform EDA on the dataset to discover patterns and relationships that will help in understanding the data better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eI1SDI4PRfr"
      },
      "source": [
        "#### **3.2.1 Univariate Analysis**\n",
        "\n",
        "Analyzing each feature inidividually to gain insights from the data and discover any outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzzjiZ7bOUmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4036621a-e2d4-4c23-f6ee-25e810e2de6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of unique userID in the dataset is :  337\n",
            "The top 5 userID in the dataset are : \n",
            " userId\n",
            "156    2179\n",
            "208    1288\n",
            "298    1127\n",
            "116    1110\n",
            "104     998\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking the feature \"userID\"\n",
        "\n",
        "total_users = len(np.unique(movie_ratings[\"userId\"]))\n",
        "print(\"The count of unique userID in the dataset is : \", total_users)\n",
        "print(\"The top 5 userID in the dataset are : \\n\", movie_ratings[\"userId\"].value_counts()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5YZPCo4tvbM"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. \"userId\" are the Users that were selected at random for inclusion and their ids have been anonymized.\n",
        "2. There are 138K+ unique users in the dataset.\n",
        "3. userId 118205 has around 9K records in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q0t8e48UPpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbee99e-fac5-4b93-e3f9-5d0bce25079e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of unique movieID in the dataset is :  5817\n",
            "The top 5 movieID in the dataset are : \n",
            " movieId\n",
            "294.0      173\n",
            "353.0      170\n",
            "477.0      143\n",
            "316.0      143\n",
            "588.0      138\n",
            "109.0      121\n",
            "1.0        120\n",
            "584.0      120\n",
            "258.0      118\n",
            "377.0      114\n",
            "149.0      113\n",
            "47.0       112\n",
            "585.0      109\n",
            "2773.0     109\n",
            "2487.0     109\n",
            "587.0      109\n",
            "603.0      109\n",
            "454.0      108\n",
            "32.0       108\n",
            "50.0       107\n",
            "524.0      107\n",
            "768.0      106\n",
            "341.0      100\n",
            "374.0      100\n",
            "583.0       99\n",
            "1243.0      98\n",
            "1174.0      97\n",
            "1172.0      97\n",
            "1185.0      96\n",
            "361.0       93\n",
            "2874.0      92\n",
            "364.0       86\n",
            "1173.0      86\n",
            "1529.0      85\n",
            "497.0       83\n",
            "844.0       82\n",
            "164.0       82\n",
            "314.0       82\n",
            "641.0       81\n",
            "592.0       81\n",
            "152.0       81\n",
            "1945.0      80\n",
            "2677.0      80\n",
            "229.0       80\n",
            "725.0       79\n",
            "590.0       79\n",
            "1662.0      79\n",
            "4898.0      78\n",
            "34.0        77\n",
            "5854.0      77\n",
            "4212.0      76\n",
            "1264.0      75\n",
            "1114.0      73\n",
            "4133.0      73\n",
            "1213.0      72\n",
            "1238.0      70\n",
            "21.0        69\n",
            "1076.0      69\n",
            "39.0        69\n",
            "326.0       68\n",
            "582.0       68\n",
            "251.0       68\n",
            "10.0        68\n",
            "1053.0      68\n",
            "1068.0      67\n",
            "290.0       67\n",
            "722.0       67\n",
            "346.0       67\n",
            "1565.0      67\n",
            "3488.0      67\n",
            "536.0       66\n",
            "7042.0      66\n",
            "538.0       65\n",
            "2544.0      65\n",
            "1181.0      65\n",
            "1840.0      64\n",
            "354.0       64\n",
            "581.0       64\n",
            "3703.0      64\n",
            "2245.0      64\n",
            "184.0       63\n",
            "110.0       63\n",
            "207.0       63\n",
            "336.0       62\n",
            "1018.0      62\n",
            "6.0         61\n",
            "286.0       61\n",
            "1170.0      61\n",
            "1481.0      61\n",
            "431.0       60\n",
            "1189.0      60\n",
            "766.0       60\n",
            "160.0       59\n",
            "2631.0      59\n",
            "2312.0      58\n",
            "451.0       58\n",
            "1646.0      57\n",
            "19.0        57\n",
            "1176.0      57\n",
            "2912.0      56\n",
            "221.0       56\n",
            "1188.0      56\n",
            "908.0       55\n",
            "1183.0      54\n",
            "291.0       54\n",
            "3903.0      54\n",
            "4900.0      53\n",
            "4791.0      53\n",
            "1885.0      52\n",
            "437.0       52\n",
            "7250.0      52\n",
            "1196.0      52\n",
            "1878.0      52\n",
            "94.0        52\n",
            "140.0       52\n",
            "4878.0      51\n",
            "6430.0      51\n",
            "1626.0      50\n",
            "2032.0      50\n",
            "1363.0      50\n",
            "2598.0      50\n",
            "1059.0      50\n",
            "3028.0      49\n",
            "548.0       49\n",
            "1279.0      49\n",
            "16.0        49\n",
            "2833.0      49\n",
            "1232.0      48\n",
            "2418.0      48\n",
            "903.0       48\n",
            "298.0       48\n",
            "8279.0      48\n",
            "1673.0      47\n",
            "11.0        47\n",
            "505.0       47\n",
            "2621.0      47\n",
            "3934.0      47\n",
            "2271.0      47\n",
            "365.0       46\n",
            "407.0       46\n",
            "17.0        46\n",
            "2207.0      46\n",
            "1197.0      46\n",
            "10170.0     46\n",
            "1585.0      46\n",
            "3061.0      46\n",
            "5253.0      46\n",
            "1929.0      45\n",
            "1928.0      45\n",
            "1357.0      45\n",
            "334.0       45\n",
            "2240.0      45\n",
            "6272.0      45\n",
            "2.0         45\n",
            "4868.0      45\n",
            "896.0       44\n",
            "1231.0      44\n",
            "1472.0      44\n",
            "4783.0      44\n",
            "1714.0      44\n",
            "1219.0      44\n",
            "776.0       44\n",
            "36.0        44\n",
            "5349.0      44\n",
            "3929.0      43\n",
            "3918.0      43\n",
            "25.0        43\n",
            "1058.0      43\n",
            "172.0       43\n",
            "103.0       43\n",
            "1533.0      43\n",
            "2625.0      43\n",
            "589.0       43\n",
            "1971.0      42\n",
            "1597.0      42\n",
            "1523.0      42\n",
            "738.0       42\n",
            "1834.0      42\n",
            "1375.0      42\n",
            "162.0       42\n",
            "471.0       42\n",
            "552.0       42\n",
            "62.0        41\n",
            "3805.0      41\n",
            "646.0       41\n",
            "1329.0      41\n",
            "2902.0      41\n",
            "1182.0      41\n",
            "315.0       41\n",
            "347.0       41\n",
            "417.0       41\n",
            "313.0       40\n",
            "439.0       40\n",
            "350.0       40\n",
            "367.0       40\n",
            "1080.0      40\n",
            "2712.0      40\n",
            "6765.0      40\n",
            "7313.0      40\n",
            "2831.0      40\n",
            "1558.0      40\n",
            "1200.0      40\n",
            "774.0       40\n",
            "1105.0      39\n",
            "1195.0      39\n",
            "12526.0     39\n",
            "2091.0      39\n",
            "697.0       39\n",
            "1327.0      39\n",
            "506.0       39\n",
            "1276.0      38\n",
            "463.0       38\n",
            "517.0       38\n",
            "2218.0      38\n",
            "1067.0      38\n",
            "1503.0      38\n",
            "185.0       38\n",
            "5718.0      38\n",
            "1617.0      37\n",
            "550.0       37\n",
            "1251.0      37\n",
            "1446.0      37\n",
            "171.0       37\n",
            "1583.0      37\n",
            "1261.0      37\n",
            "4801.0      37\n",
            "1194.0      37\n",
            "6235.0      37\n",
            "233.0       37\n",
            "494.0       37\n",
            "1069.0      36\n",
            "1620.0      36\n",
            "1220.0      36\n",
            "432.0       36\n",
            "2966.0      36\n",
            "1458.0      36\n",
            "159.0       36\n",
            "3884.0      36\n",
            "1340.0      35\n",
            "1361.0      35\n",
            "2607.0      35\n",
            "264.0       35\n",
            "7.0         35\n",
            "195.0       35\n",
            "58.0        35\n",
            "1917.0      35\n",
            "3941.0      35\n",
            "167.0       35\n",
            "888.0       35\n",
            "1204.0      35\n",
            "3856.0      35\n",
            "1010.0      35\n",
            "2706.0      35\n",
            "1572.0      35\n",
            "3090.0      34\n",
            "7954.0      34\n",
            "1177.0      34\n",
            "3663.0      34\n",
            "9938.0      34\n",
            "1556.0      34\n",
            "1292.0      34\n",
            "352.0       34\n",
            "1274.0      34\n",
            "3533.0      34\n",
            "2533.0      34\n",
            "6261.0      33\n",
            "1160.0      33\n",
            "2269.0      33\n",
            "1208.0      33\n",
            "772.0       33\n",
            "1239.0      33\n",
            "1073.0      33\n",
            "7770.0      33\n",
            "2458.0      33\n",
            "429.0       33\n",
            "1350.0      33\n",
            "339.0       32\n",
            "150.0       32\n",
            "12747.0     32\n",
            "491.0       32\n",
            "1190.0      32\n",
            "2627.0      32\n",
            "3321.0      32\n",
            "1364.0      32\n",
            "5322.0      32\n",
            "1175.0      32\n",
            "907.0       32\n",
            "818.0       32\n",
            "7762.0      32\n",
            "70.0        32\n",
            "1346.0      32\n",
            "22.0        32\n",
            "5282.0      32\n",
            "3393.0      31\n",
            "2614.0      31\n",
            "482.0       31\n",
            "373.0       31\n",
            "3661.0      31\n",
            "2386.0      31\n",
            "1940.0      31\n",
            "1546.0      31\n",
            "1255.0      31\n",
            "2017.0      31\n",
            "5891.0      31\n",
            "48.0        31\n",
            "157.0       31\n",
            "1029.0      30\n",
            "1663.0      30\n",
            "1215.0      30\n",
            "280.0       30\n",
            "2900.0      30\n",
            "1258.0      30\n",
            "330.0       30\n",
            "223.0       30\n",
            "6602.0      30\n",
            "904.0       30\n",
            "1017.0      30\n",
            "111.0       30\n",
            "1207.0      30\n",
            "540.0       30\n",
            "2805.0      29\n",
            "250.0       29\n",
            "1923.0      29\n",
            "937.0       29\n",
            "2184.0      29\n",
            "5918.0      29\n",
            "1344.0      29\n",
            "2719.0      29\n",
            "3855.0      29\n",
            "1871.0      29\n",
            "263.0       29\n",
            "3089.0      29\n",
            "1918.0      29\n",
            "10601.0     29\n",
            "591.0       29\n",
            "892.0       29\n",
            "4153.0      29\n",
            "1223.0      29\n",
            "2323.0      29\n",
            "1495.0      29\n",
            "1998.0      29\n",
            "5203.0      29\n",
            "2322.0      28\n",
            "2615.0      28\n",
            "1376.0      28\n",
            "3438.0      28\n",
            "2572.0      28\n",
            "5520.0      28\n",
            "1670.0      28\n",
            "468.0       28\n",
            "1634.0      27\n",
            "52.0        27\n",
            "3932.0      27\n",
            "144.0       27\n",
            "1793.0      27\n",
            "2371.0      27\n",
            "2616.0      27\n",
            "3.0         27\n",
            "15535.0     27\n",
            "1708.0      27\n",
            "4214.0      27\n",
            "1684.0      27\n",
            "2340.0      27\n",
            "259.0       27\n",
            "3074.0      27\n",
            "2237.0      27\n",
            "10887.0     27\n",
            "1914.0      26\n",
            "3167.0      26\n",
            "24.0        26\n",
            "45.0        26\n",
            "1179.0      26\n",
            "244.0       26\n",
            "5.0         26\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking the feature \"movieID\"\n",
        "\n",
        "total_movies = len(np.unique(movie_ratings[\"movieId\"]))\n",
        "print(\"The count of unique movieID in the dataset is : \", total_movies)\n",
        "print(\"The top 5 movieID in the dataset are : \\n\", movie_ratings[\"movieId\"].value_counts()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr1Gz-Ctx2gX"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. \"movieId\" represents the movies with at least one rating or tag in the dataset.\n",
        "2. There are close to 26K+ unique movies in the dataset.\n",
        "3. movieId 294, 353, 316 and 588 are few popular movies which has been rated over 60K times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IIIt4wtdNyi"
      },
      "outputs": [],
      "source": [
        "# Helper function to Change the numeric label in terms of Millions\n",
        "\n",
        "def changingLabels(number):\n",
        "\n",
        "    return str(number/10**6) + \"M\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM1u-zOzVQiT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "997095b6-f793-4bf2-b773-5eef04d216bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Checking the feature \"rating\"\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "#set the style to darkgrid with a grid\n",
        "\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "# fig, axes: Creates a large plot area (canvas) where we can draw.\n",
        "# figsize=(25, 5): The size of the plot is set to be wide (25 units) and not very tall (5 units).\n",
        "# sharey=True: If there were more plots, they would share the same y-axis scale.\n",
        "\n",
        "sns.countplot(x =\"rating\", data=movie_ratings, ax=axes)\n",
        "axes.set_yticklabels([changingLabels(num) for num in axes.get_yticks()])\n",
        "#set custom labels in the y axis\n",
        "#changingLabels(num): This function, which we defined earlier, formats the y-axis labels (e.g., changing 1000000 to 1M).\n",
        "for p in axes.patches:\n",
        "    axes.annotate('{}'.format(p.get_height()), (p.get_x()+0.2, p.get_height()+100))\n",
        "\n",
        "# #loops over each bar in the plot\n",
        "# p.get_height(): Gets the height (count) of the bar and displays it as text on the bar.\n",
        "# (p.get_x() + 0.2, p.get_height() + 100): Positions the text slightly to the right of the bar and above its top.\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "#to make numbers and labels on the x and y axes bigger for better readability\n",
        "\n",
        "plt.title(\"Distribution of Ratings in the dataset\", fontsize = 20)\n",
        "plt.xlabel(\"Ratings\", fontsize = 10)\n",
        "plt.ylabel(\"Counts(in Millions)\", fontsize = 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUhy3vwgyaci"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The ratings given by users to movies lies in between 0.5 to 5.\n",
        "2. A high proportion of the movies have been rated 3, 3.5 or 4 by the users.\n",
        "3. The distribution of ratings look a bit left skewed as large proportion of ratings is in between 3 to 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiL5J031WvkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b348403e-5810-47df-9a68-92e904c2d207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of unique date in the dataset is :  1324\n",
            "The first rating was given on :  1970-01-01\n",
            "The latest rating was given on :  2015-03-30\n",
            "The top 5 date in the dataset are : \n",
            " date\n",
            "1999-12-11    1032\n",
            "2005-11-23     744\n",
            "2001-06-13     660\n",
            "2000-08-03     516\n",
            "1999-12-13     480\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking the feature \"date\"\n",
        "\n",
        "print(\"The count of unique date in the dataset is : \", movie_ratings[\"date\"].nunique())\n",
        "print(\"The first rating was given on : \", movie_ratings[\"date\"].min())\n",
        "print(\"The latest rating was given on : \", movie_ratings[\"date\"].max())\n",
        "print(\"The top 5 date in the dataset are : \\n\", movie_ratings[\"date\"].value_counts()[:5])\n",
        "#Return a Series containing counts of unique values\n",
        "#The resulting object will be in descending order so that the first element is the most frequently-occurring element. Excludes NA values by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKW2vZENzIvR"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. There are ~7K unique dates when the ratings were given by a user to a movie.\n",
        "2. The first rating was given on 1995-01-09 and the latest rating was given on 2015-03-31.\n",
        "3. Around 91K+ ratings were observed on 2000-11-20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua2AI1OUW6Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b1f8f2-ec9d-4ade-c644-519ae38c22bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of unique title in the dataset is :  5815\n",
            "The top 5 title in the dataset are : \n",
            " title\n",
            "Pulp Fiction (1994)                 173\n",
            "Forrest Gump (1994)                 170\n",
            "Shawshank Redemption, The (1994)    143\n",
            "Jurassic Park (1993)                143\n",
            "Silence of the Lambs, The (1991)    138\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking the feature \"title\"\n",
        "\n",
        "movie_list = movie_ratings[\"title\"].unique()\n",
        "print(\"The count of unique title in the dataset is : \", movie_ratings[\"title\"].nunique())\n",
        "print(\"The top 5 title in the dataset are : \\n\", movie_ratings[\"title\"].value_counts()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_p8YjqM79lI"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. There are 26K+ unique movie titles in the dataset.\n",
        "2. Pulp Fiction, Forrest Gump, Shawshank Redemption and Silence of the Lambs are the top 4 movies in terms of no. of ratings received which are over 60K+ for each one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj6XTZErXPrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "54b0ac34-6501-4b29-8110-ba8a8b9d380a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'float' object has no attribute 'split'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-206689dad1b6>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#simply increment the count of the genre by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmovie_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"genres\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExtractGenres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#to each value in the genres column of the movie_ratings dataset ; This goes through all the rows and extracts and counts the genres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Genres Extracted from the dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-206689dad1b6>\u001b[0m in \u001b[0;36mExtractGenres\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mExtractGenres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0;31m#if x is \"Adventure|Action|Comedy\", it splits into [\"Adventure\", \"Action\", \"Comedy\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;31m#go through each genre in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
          ]
        }
      ],
      "source": [
        "# Extract unique Genres along with their count\n",
        "\n",
        "unique_genres = {}\n",
        "#empty dictionary\n",
        "\n",
        "def ExtractGenres(x):\n",
        "    for g in x.split(\"|\"):\n",
        "      #if x is \"Adventure|Action|Comedy\", it splits into [\"Adventure\", \"Action\", \"Comedy\"]\n",
        "      #go through each genre in the list\n",
        "        if g not in unique_genres.keys():\n",
        "          #we ll check if the genre exists as key in the unique value dictionary\n",
        "            unique_genres[g] = 1\n",
        "            #the first occurence of the genre\n",
        "        else:\n",
        "            unique_genres[g] = unique_genres[g] + 1\n",
        "            #simply increment the count of the genre by one\n",
        "\n",
        "movie_ratings[\"genres\"].apply(ExtractGenres)\n",
        "#to each value in the genres column of the movie_ratings dataset ; This goes through all the rows and extracts and counts the genres\n",
        "print(\"Genres Extracted from the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE1fM8wTauFS"
      },
      "outputs": [],
      "source": [
        "# Visualizing the feature \"Genres\"\n",
        "\n",
        "genres_df = pd.DataFrame(list(unique_genres.items()))\n",
        "#if unique_genres is {'Action': 10, 'Comedy': 7}, then unique_genres.items() will output [('Action', 10), ('Comedy', 7)]\n",
        "#We convert the items of the dictionary to a list of tuples and then create a DataFrame from the list with the tuples.\n",
        "\n",
        "genres_df.columns = [\"Genre\", \"Count\"]\n",
        "#label the columns\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 8), sharey=True)\n",
        "#1 single space for a single plot\n",
        "\n",
        "sns.barplot(y=\"Count\", x=\"Genre\", data=genres_df, ax=axes)\n",
        "#we've plotted a bar plot over the figure\n",
        "\n",
        "axes.set_yticklabels([changingLabels(num) for num in axes.get_yticks()])\n",
        "#retrieves the y-axis tick positions, applies a transformation (through changingLabels) to each tick(y label), and then sets those transformed values as the new y-axis labels\n",
        "\n",
        "for p in axes.patches:\n",
        "  #for each bar in the plot\n",
        "    axes.annotate('{}'.format(int(p.get_height())), (p.get_x(), p.get_height()+100))\n",
        "    #gets the integer value of the height of each bar and positions it to the center and a little higher than the plot itself\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "#size of the text displayed\n",
        "\n",
        "plt.title(\"Distribution of Genres in the dataset\", fontsize = 20)\n",
        "plt.xlabel(\"Genres\", fontsize = 15)\n",
        "plt.xticks(rotation=60, fontsize=10)\n",
        "#roatates the value on the x label\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylabel(\"Counts (in Millions)\", fontsize = 15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ACrmXF68wZr"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. There are 19 different genres of movies while there are few whose genre has not been mentioned.\n",
        "2. Drama, Comedy, Action and Thriller are top 4 genres of movies present in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZMqYP1wUPvy"
      },
      "outputs": [],
      "source": [
        "movie_ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfT4KHdm9on5"
      },
      "source": [
        "#### **3.2.2 Train & test Splitting**\n",
        "\n",
        "Splitting the data into train and test sets before proceeding towards further EDA and Feature Engineering."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_QMY5ILa5RHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abdj3LNVUThD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the local file path where data will be saved\n",
        "file_path = \"/content\"  # This is the default working directory in Colab\n",
        "\n",
        "# Check and create TrainData if it doesn't exist\n",
        "if not os.path.isfile(file_path + \"/TrainData.pkl\"):\n",
        "    print(\"Creating Train Data and saving it..\")\n",
        "    movie_ratings.iloc[:int(movie_ratings.shape[0] * 0.80)].to_pickle(file_path + \"/TrainData.pkl\")\n",
        "    #This line selects the first 80% of the data from the movie_ratings DataFrame for the training set.\n",
        "    # movie_ratings.shape[0] * 0.80 gives the number of rows that represent 80% of the dataset.\n",
        "    # iloc[:int(...)] selects the rows from index 0 up to 80% of the dataset.\n",
        "    #shape fetches the number of rows here\n",
        "    # 80% of the data is used for training\n",
        "    # 20% of the data is used for testing\n",
        "\n",
        "    Train_Data = pd.read_pickle(file_path + \"/TrainData.pkl\")\n",
        "    Train_Data.reset_index(drop=True, inplace=True)\n",
        "else:\n",
        "    print(\"Loading Train Data..\")\n",
        "    Train_Data = pd.read_pickle(file_path + \"/TrainData.pkl\")\n",
        "    Train_Data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Check and create TestData if it doesn't exist\n",
        "if not os.path.isfile(file_path + \"/TestData.pkl\"):\n",
        "    print(\"Creating Test Data and saving it..\")\n",
        "    movie_ratings.iloc[int(movie_ratings.shape[0] * 0.80):].to_pickle(file_path + \"/TestData.pkl\")\n",
        "    #int(movie_ratings.shape[0] * 0.80) calculates the index from where to start the test data (80% of the dataset).\n",
        "    Test_Data = pd.read_pickle(file_path + \"/TestData.pkl\")\n",
        "    Test_Data.reset_index(drop=True, inplace=True)\n",
        "else:\n",
        "    print(\"Loading Test Data..\")\n",
        "    Test_Data = pd.read_pickle(file_path + \"/TestData.pkl\")\n",
        "    Test_Data.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npkvqmeHfXHu"
      },
      "outputs": [],
      "source": [
        "Train_Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVeQT3u0Wqdo"
      },
      "outputs": [],
      "source": [
        "# Creating list of unique movies from Train Set\n",
        "\n",
        "movie_list_in_training = Train_Data.drop_duplicates(subset=[\"title\"], keep=\"first\")[[\"movieId\", \"title\", \"genres\"]]\n",
        "#keeps the first occurence of that \"title\" from the title column\n",
        "#After removing duplicates, this selects the relevant columns (movieId, title, and genres) from the dataset.\n",
        "#This will help in having only essential information for each movie: the movieId, the title, and the genres\n",
        "\n",
        "movie_list_in_training = movie_list_in_training.reset_index(drop=True)\n",
        "#reset the indices to default\n",
        "movie_list_in_training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87v_BcQfibPI"
      },
      "outputs": [],
      "source": [
        "# Checking the basic statistics for the training data\n",
        "\n",
        "print(\"Total Train Data..\")\n",
        "print(\"Total number of movie ratings in train data : \", str(Train_Data.shape[0]))\n",
        "print(\"Number of unique users in train data : \", str(len(np.unique(Train_Data[\"userId\"]))))\n",
        "print(\"Number of unique movies in train data : \", str(len(np.unique(Train_Data[\"movieId\"]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNSaqdZQh1qU"
      },
      "source": [
        "#### **3.2.3 Bi-variate Analysis**\n",
        "\n",
        "Analyzing multiple features together to discover relations, correlations and patterns.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO_gOCdX1giz"
      },
      "source": [
        "---\n",
        "\n",
        "#####**1. Analyzing the Distribution of Ratings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "234Iut9-uKMf"
      },
      "outputs": [],
      "source": [
        "# Checking basic statistics for \"rating\"\n",
        "\n",
        "print(\"The basic statistics for the feature is : \\n\", Train_Data[\"rating\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgysPhqifaBO"
      },
      "outputs": [],
      "source": [
        "# Visualizing the \"rating\" for the train set\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "#drawing space for a single plot, with fig width and height, cna draw multiple plots on the same space\n",
        "\n",
        "sns.countplot(x=\"rating\", data=Train_Data, ax=axes)\n",
        "#rating countplot\n",
        "axes.set_yticklabels([changingLabels(num) for num in axes.get_yticks()])\n",
        "#custom labels for the y axis, by converting the large numerical values into value+million\n",
        "\n",
        "for p in axes.patches:\n",
        "  #for each bar in the barplot\n",
        "    axes.annotate('{}'.format(p.get_height()), (p.get_x()+0.2, p.get_height()+100))\n",
        "    #annotate or provide the height of the bars, or the y label values exact, positioned towards the center.\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Distribution of Ratings in the training dataset\", fontsize = 20)\n",
        "plt.xlabel(\"Ratings\", fontsize = 10)\n",
        "plt.ylabel(\"Counts(in Millions)\", fontsize = 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiRMfRDjuCj_"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The distribution of ratings seems to be similar as before.\n",
        "2. The mean and median value are very close to around 3.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAPcjPED14xc"
      },
      "source": [
        "---\n",
        "\n",
        "#####**2. Analyzing the number of ratings with date.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeIXk9WhiQNY"
      },
      "outputs": [],
      "source": [
        "# Extracting the day of week from the date when rating was provided\n",
        "import pandas as pd\n",
        "\n",
        "Train_Data[\"date\"] = pd.to_datetime(Train_Data[\"date\"], errors='coerce')\n",
        "#This function converts the values in the \"date\" column to datetime objects. This is necessary because the data may have been read as strings or in an inconsistent format,\n",
        "#and converting it to datetime makes it easier to work with and extract specific information like the day of the week.\n",
        "#any invalid date values (e.g., improperly formatted dates), they are turned into NaT (Not a Time)\n",
        "\n",
        "Train_Data[\"DayOfWeek\"] = Train_Data[\"date\"].dt.strftime('%A')\n",
        "#accesses the datetime attributes of the \"date\" column (.dt)\n",
        "#date into the full name of the day of the week and stored in the day of week column\n",
        "\n",
        "Train_Data[\"Weekday\"] = Train_Data[\"date\"].apply(lambda x : 1 if x.dayofweek > 5 else 0)\n",
        "#binary attribute to identify is the day of the week is a weekday(1) or a weekend(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8VtMZ4Dz9Db"
      },
      "outputs": [],
      "source": [
        "# Converting the number into 'Ks.\n",
        "#previously we did the same for millions\n",
        "def ChangingLabelsInK(number):\n",
        "    return str(int(number/10**3)) + \"K\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKga7VY8iQTs"
      },
      "outputs": [],
      "source": [
        "# Visualizing the count of total ratings made per month\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "#similarly set the background to dark, and enable grid\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "#create a plot in a single column and row, allocate 25 spaces horizontally, and 5 vertically, allow other plots to be plotted over the same space\n",
        "\n",
        "axes = Train_Data.resample(\"m\", on = \"date\")[\"rating\"].count().plot()\n",
        "#Train_Data.resample(\"m\", on=\"date\"): This resamples the data by month. The argument \"m\" stands for monthly resampling,\n",
        "#and on=\"date\" tells the code to resample based on the \"date\" column.\n",
        "# [\"rating\"].count(): After resampling the data by month, this counts the number of ratings made each month.\n",
        "# .plot(): This plots the resampled data (the count of ratings per month) on the axes.\n",
        "\n",
        "axes.set_yticklabels([ChangingLabelsInK(num) for num in axes.get_yticks()])\n",
        "#this time we consider values in thousands and hence we change the y label values in terms of thousands.\n",
        "\n",
        "axes.set_title(\"Count of Total Ratings per Month\", fontsize = 20)\n",
        "axes.set_xlabel(\"Date\", fontsize = 15)\n",
        "axes.set_ylabel(\"Number of Ratings (in thousands)\", fontsize = 15)\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.show()\n",
        "\n",
        "# The y-axis labels represent the count of ratings over time, so these values are continuous\n",
        "#line plot is used in this scenario because you're trying to visualize how the count of ratings changes over time, specifically by month\n",
        "#time series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rgONWsH2MmW"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The no. of ratings per month was very high in few of the months between 1996 to 1998.\n",
        "2. Similarly, post the 2000s, there are few month that have few months of very high no. of ratings.\n",
        "3. The count remains steady after 2001 till 2010, with a spike at few month of 2006."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mbeBZMYVBjz"
      },
      "outputs": [],
      "source": [
        "# Visualizing the count of ratings by weekday\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.barplot(x=\"Weekday\", y=\"rating\" , data=Train_Data.groupby(by=[\"Weekday\"], as_index=False)[\"rating\"].count(), ax=axes)\n",
        "#we use group by to create a bar plot segragating the weekdays and weekends.\n",
        "#[\"rating\"].count(): After grouping by \"Weekday\", this counts how many ratings were made for each group (i.e., how many ratings occurred on weekdays and weekends).\n",
        "#in totality, This gives a new dataframe where the \"Weekday\" column shows the group (either 0 for weekdays or 1 for weekends), and the \"rating\" column shows the total number of ratings for each group.\n",
        "\n",
        "for p in axes.patches:\n",
        "    axes.annotate('{}'.format(int(p.get_height())), (p.get_x(), p.get_height()+100))\n",
        "    #again this annotates the heights of the bars on the plot at specified position.\n",
        "\n",
        "axes.set_yticklabels([changingLabels(num) for num in axes.get_yticks()])\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Distribution of number of ratings by Weekday\", fontsize = 20)\n",
        "plt.xlabel(\"Weekday\", fontsize = 15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylabel(\"Counts (in Millions)\", fontsize = 15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or8vWOp-cFSk"
      },
      "outputs": [],
      "source": [
        "# Visualizing the count of ratings by individual days of the week\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.barplot(x=\"DayOfWeek\", y=\"rating\" , data=Train_Data.groupby(by=[\"DayOfWeek\"], as_index=False)[\"rating\"].count(), ax=axes)\n",
        "#compare by days of the week -> get the count of the ratings and plot in a bar graph.\n",
        "\n",
        "for p in axes.patches:\n",
        "    axes.annotate('{}'.format(int(p.get_height())), (p.get_x(), p.get_height()+100))\n",
        "    #annoate the height on the specified positions on each bar.\n",
        "\n",
        "axes.set_yticklabels([changingLabels(num) for num in axes.get_yticks()])\n",
        "#custom y labels instead of the default labels\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Distribution of number of ratings by individual days\", fontsize = 20)\n",
        "plt.xlabel(\"Days\", fontsize = 15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylabel(\"Counts (in Millions)\", fontsize = 15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE0sHGz3dLy8"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The no. of ratings does not vary too much the days of the week.\n",
        "2. \"Monday\" and \"Tuesday\" clearly has more no. of ratings than any other days.\n",
        "3. The number of ratings in weekend is clearly extremly less than weekdays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYZjWSsQekK5"
      },
      "source": [
        "---\n",
        "\n",
        "#####**3. Analyzing the average ratings by date.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXhL3W7rfOv7"
      },
      "outputs": [],
      "source": [
        "# Visualizing the average ratings by weekday\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.boxplot(x=\"Weekday\", y=\"rating\" , data=Train_Data, ax=axes)\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Boxplot of Average Ratings by Weekday\", fontsize = 20)\n",
        "plt.xlabel(\"Weekday\", fontsize = 15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.ylabel(\"Ratings\", fontsize = 15)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHspQk46gSnM"
      },
      "outputs": [],
      "source": [
        "# Visualizing the average ratings by individual Days of the Week\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.boxplot(x=\"DayOfWeek\", y=\"rating\", data=Train_Data, ax=axes)\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Boxplot of Average Ratings by Days of Week\", fontsize = 20)\n",
        "plt.xlabel(\"Days\", fontsize = 15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.ylabel(\"Ratings\", fontsize = 15)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Lb91l3giuY"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The average ratings given by the user does not seem to differ by weekday and weekends.\n",
        "2. Even when we plot the average ratings by individual days, they seem to be similar for all the individual days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtwVLiS2F_3"
      },
      "source": [
        "---\n",
        "\n",
        "#####**4. Analyzing the Ratings given by Users.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6lbT7PilnzO"
      },
      "outputs": [],
      "source": [
        "# Calculating the number of ratings given by individual users\n",
        "\n",
        "no_of_rated_movies_per_user = Train_Data.groupby(by=[\"userId\"], as_index=False)[\"rating\"].count().sort_values(by=\"rating\", ascending=False)\n",
        "#grouping by users, counting number of ratings given by each user  in descending order.\n",
        "no_of_rated_movies_per_user.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBr10x8vCUT9"
      },
      "outputs": [],
      "source": [
        "# Visualizing the count of ratings by individual users\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "#fig, axes: fig is the Figure object, representing the overall container for all plots, while axes is the Axes object, representing the specific plot area.\n",
        "#plt.subplots(1, 1): Creates a single subplot (1 row, 1 column). The result is a single Axes object (not an array of Axes, since there’s only one plot).\n",
        "#figsize=(25, 5): Specifies the size of the figure in inches. The width is set to 25 inches, and the height is set to 5 inches, resulting in a very wide, short plot.\n",
        "#sharey=True: Ensures that if there were multiple subplots, they would share the same y-axis scale. Since there’s only one plot here, this parameter does not have much effect.\n",
        "sns.barplot(x=\"userId\", y=\"rating\" , data=no_of_rated_movies_per_user[:15], ax=axes)\n",
        "#picks up only 15 rows\n",
        "for p in axes.patches:\n",
        "  #for each bar in the bar plot\n",
        "    axes.annotate('{}'.format(int(p.get_height())), (p.get_x(), p.get_height()+100))\n",
        "    #annotate the height to the bars\n",
        "\n",
        "axes.set_yticklabels([ChangingLabelsInK(num) for num in axes.get_yticks()])\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Number of ratings for Top 15 Users\", fontsize = 20)\n",
        "plt.xlabel(\"UserID\", fontsize = 15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylabel(\"Counts\", fontsize = 15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0lgJDHmlG6a"
      },
      "outputs": [],
      "source": [
        "# Visualizing the count of ratings by individual users\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(25, 8))\n",
        "#two subplots, one row, two columns\n",
        "\n",
        "sns.kdeplot(no_of_rated_movies_per_user[\"rating\"], shade = True, ax = axes[0])\n",
        "#uses Seaborn's kdeplot function to create a Kernel Density Estimate (KDE) plot,\n",
        "#which shows the probability density of rating values from the no_of_rated_movies_per_user dataset\n",
        "#we can simply use axes if there is a single subplot\n",
        "axes[0].set_title(\"PDF\", fontsize = 18)\n",
        "axes[0].set_xlabel(\"Number of Ratings by users\", fontsize = 18)\n",
        "axes[0].tick_params(labelsize = 15)\n",
        "\n",
        "sns.kdeplot(no_of_rated_movies_per_user[\"rating\"], shade = True, cumulative = True, ax = axes[1])\n",
        "#This option turns the KDE plot into a cumulative distribution function (CDF). Instead of showing the density at each point,\n",
        "#it shows the cumulative probability, giving a rising curve that indicates the cumulative probability of the ratings up to each point.\n",
        "\n",
        "axes[1].set_title(\"CDF\", fontsize = 18)\n",
        "axes[1].set_xlabel(\"Number of Ratings by user\", fontsize = 18)\n",
        "axes[1].tick_params(labelsize = 15)\n",
        "\n",
        "fig.subplots_adjust(wspace=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sharp peak near zero**: The PDF shows that the majority of users have rated only a few items, as indicated by the high peak near zero. This suggests that most users provide only a small number of ratings.\n",
        "\n",
        "**Long tail**: There is a long tail extending towards the right, which indicates that while most users rate very few items, a small number of users rate a lot more items (potentially power users or very active raters).\n",
        "\n",
        "**Density decreasing rapidly**: The density drops quickly as the number of ratings increases, confirming that high rating counts are rare.\n",
        "\n",
        "\n",
        "\n",
        "**CDF**\n",
        "\n",
        "**Steep initial rise**: The CDF rises steeply near zero, indicating that a large percentage of users fall within the lower range of ratings. This confirms the PDF observation that many users rate only a few items.\n",
        "\n",
        "**Plateau towards 1**: The curve flattens and approaches a cumulative density of 1 (or 100%) as it reaches the higher number of ratings. This means that almost all users are accounted for by the time the number of ratings reaches a certain point on the x-axis.\n",
        "\n",
        "**Interpretation of 80-90% range**: Based on the CDF, it’s likely that around 80-90% of users rate fewer than a specific threshold (e.g., around 1000 ratings), with only a very small proportion rating significantly more."
      ],
      "metadata": {
        "id": "yJm1LWALZx5R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6QF5E8wzBxm"
      },
      "outputs": [],
      "source": [
        "# Checking the basic statistics for the number of ratings per user\n",
        "\n",
        "print(\"Information about no. of ratings by users : \\n\", no_of_rated_movies_per_user[\"rating\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRs_EUc6zUan"
      },
      "outputs": [],
      "source": [
        "quantiles = no_of_rated_movies_per_user[\"rating\"].quantile(np.arange(0.9, 1.01,0.01))\n",
        "qvalue = np.arange(0.9, 1.01,0.01)\n",
        "#Creates an array of values from 0.9 to 1.0 (inclusive) with a step of 0.01.\n",
        "#this represents the range of quantiles we want to calculate, from the 90th percentile (0.9) to the 100th percentile (1.0)\n",
        "\n",
        "for ctr in qvalue:\n",
        "    print(\"The {}th quantile value is : {}\".format(int(ctr*100), quantiles[ctr]))\n",
        "    #we're putting the values of the quantiles mutliplied by 100 into the placeholders, and then printing their values in the second placeholder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TLJd4RAy-kJ"
      },
      "outputs": [],
      "source": [
        "# Plotting the quantile values\n",
        "quantiles = no_of_rated_movies_per_user[\"rating\"].quantile(np.arange(0, 1.01,0.01))\n",
        "\n",
        "fig = plt.figure(figsize=(25, 5))\n",
        "# figure of the specified size\n",
        "\n",
        "axes = fig.add_axes([0.1,0.1,1,1])\n",
        "# adds axes to the figure with specific dimensions, allowing for customization of the plotting area.\n",
        "\n",
        "axes.set_title(\"Quantile values of Ratings Per User\", fontsize=20)\n",
        "axes.set_xlabel(\"Quantiles\", fontsize=20)\n",
        "axes.set_ylabel(\"Ratings Per User\", fontsize=20)\n",
        "axes.plot(quantiles)\n",
        "\n",
        "plt.scatter(x=quantiles.index[::5], y=quantiles.values[::5], c=\"blue\", s=70, label=\"quantiles with 0.05 intervals\")\n",
        "#x values are the quantiles' indices separated by 0.05\n",
        "#y values are the vaalues of those quantiles\n",
        "\n",
        "plt.scatter(x=quantiles.index[::25], y=quantiles.values[::25], c=\"red\", s=70, label=\"quantiles with 0.25 intervals\")\n",
        "plt.legend(loc='upper left', fontsize=20)\n",
        "#quantitles with separation of 0.25\n",
        "#y values are the values of the corresponding quantiles.\n",
        "\n",
        "\n",
        "for x, y in zip(quantiles.index[::25], quantiles.values[::25]):\n",
        "  #zips together slices of the index and values from the quantiles data, with every 25th value from the index and values.\n",
        "    plt.annotate(text='({},{})'.format(x, int(y)), xy=(x, y), fontweight='bold', fontsize=16, xytext=(x-0.05, y+180))\n",
        "    #here we're trying to annotate the plot with the quantile position, and its value.\n",
        "\n",
        "axes.tick_params(labelsize=15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1mByTJWktMX"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The top 10 users tend to have rated more than 4K times, which seems bit extreme behaviour.\n",
        "2. The userId 118205 has rated over 7K+ times, which seems surprising.\n",
        "3. From the KDE plot, it is clearly evident that the number of ratings is highly right skewed, and most of the user's ratings is between 0-1000.\n",
        "4. Similarly, above CDF graph shows that almost 99% of users give very few ratings.\n",
        "5. The mean no. of ratings a user gives is 142 while the median is 69.\n",
        "6. The no. of movies start to increase drastically from 90th percentile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzb7hpuZ7p0B"
      },
      "outputs": [],
      "source": [
        "# Calculating average ratings given by individual users\n",
        "\n",
        "avg_ratings_per_user = Train_Data.groupby(by = [\"userId\"], as_index=False)[\"rating\"].mean()\n",
        "#group by the users, and then calculate the average of the total ratings by each user\n",
        "avg_ratings_per_user = avg_ratings_per_user.reset_index(drop=True)\n",
        "#set index to default values\n",
        "avg_ratings_per_user = avg_ratings_per_user.merge(no_of_rated_movies_per_user[[\"userId\", \"rating\"]], how=\"left\", on=\"userId\")\n",
        "#no of rated movies per user is basically no of movies that the user has rated dataframe\n",
        "#after left join, a \"rating\" column will have been added to the dataframe.\n",
        "# we ll have the user id, avg rating by the user, and the no of movies that the user has rated.\n",
        "\n",
        "avg_ratings_per_user.rename(columns={\"rating_x\":\"avg_rating\", \"rating_y\": \"num_of_rating\"}, inplace=True)\n",
        "#rating x to avg_rating\n",
        "#rating y to num_of rating\n",
        "\n",
        "avg_ratings_per_user = avg_ratings_per_user.sort_values(\"num_of_rating\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqFXz5W28K2x"
      },
      "outputs": [],
      "source": [
        "# Visualizing the average ratings by individual Days of the Week\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.barplot(x=\"userId\", y=\"avg_rating\", data=avg_ratings_per_user[:15], ax=axes)\n",
        "\n",
        "for p in axes.patches:\n",
        "    axes.annotate('{}'.format(round(p.get_height(), 2)), (p.get_x()+0.3, p.get_height()))\n",
        "    #average ratings rounded off to two decimal places.\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Average Ratings by top 15 Users\", fontsize = 20)\n",
        "plt.xlabel(\"User ID\", fontsize = 15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.ylabel(\"Rating\", fontsize = 15)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeyRAPQe88qH"
      },
      "outputs": [],
      "source": [
        "# Plotting the PDF and CDF for Avg. rating by Users\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(25, 5))\n",
        "fig.suptitle(\"Avg Ratings per User\", fontsize=25)\n",
        "\n",
        "sns.distplot(avg_ratings_per_user[\"avg_rating\"], hist = False, ax = axes[0], label = \"PDF\")\n",
        "axes[0].set_title(\"PDF\", fontsize = 18)\n",
        "axes[0].set_xlabel(\"Average Ratings by users\", fontsize = 18)\n",
        "axes[0].tick_params(labelsize = 15)\n",
        "#can be used for both a histogram and a kde\n",
        "#no cumulative distributions herehere is\n",
        "\n",
        "sns.kdeplot(avg_ratings_per_user[\"avg_rating\"], cumulative = True, ax = axes[1], shade=True, label = \"CDF\")\n",
        "#axes 1 for the second column\n",
        "axes[1].set_title(\"CDF\", fontsize = 18)\n",
        "axes[1].set_xlabel(\"Average Ratings by user\", fontsize = 18)\n",
        "axes[1].tick_params(labelsize = 15)\n",
        "#used for smooth distribution estimation, which is helpful for understanding the shape\n",
        "#of the distribution of data, especially when you want to avoid the \"blocky\" appearance of a histogram.\n",
        "\n",
        "fig.subplots_adjust(wspace=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szikNlHGAApS"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. User ID 125794 has the highest avg. rating of 3.81.\n",
        "2. The pdf of average ratings given by a user seems to be a bit left skewed, with most of the values centered around 3.5 to 4.\n",
        "3. THe cdf also shows that avg. ratings is most frequent in between 3 to 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6noWWxg2yp2"
      },
      "source": [
        "---\n",
        "\n",
        "#####**5. Analyzing the Ratings given to the Movies.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66iNX45A3uPT"
      },
      "outputs": [],
      "source": [
        "# Calculating count of ratings received for movies\n",
        "\n",
        "no_of_ratings_per_movie = Train_Data.groupby(by = [\"movieId\", \"title\"], as_index=False)[\"rating\"].count().sort_values(by=[\"rating\"], ascending = False)\n",
        "#we re counting and sorting the ratings received by each individual movie in descending order.\n",
        "no_of_ratings_per_movie = no_of_ratings_per_movie.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmBJZxHC3-4V"
      },
      "outputs": [],
      "source": [
        "# Visualizing the number of ratings for the movies\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "fig = plt.figure(figsize = (25, 5))\n",
        "#figure object with width 25 and 5\n",
        "\n",
        "axes = fig.add_axes([0.1, 0.1, 1, 1])\n",
        "# 0.1: The x-position of the lower-left corner of the axes (10% from the left).\n",
        "# 0.1: The y-position of the lower-left corner of the axes (10% from the bottom).\n",
        "# 1: The width of the axes (100% of the available space).\n",
        "# 1: The height of the axes (100% of the available space).\n",
        "\n",
        "plt.title(\"Number of Ratings Per Movie\", fontsize = 20)\n",
        "plt.xlabel(\"Movie\", fontsize = 15)\n",
        "plt.ylabel(\"Count of Ratings\", fontsize = 15)\n",
        "\n",
        "plt.plot(no_of_ratings_per_movie[\"rating\"].values)\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "axes.set_xticklabels([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iipBg8fJtgUr"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. It is quite clear that there are some movies which are very popular and were rated by many users as comapared to other movies which has caused the plot to be skewed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6JlOn_sttfb"
      },
      "outputs": [],
      "source": [
        "# Visualizing top 5 movies heavily rated movies.\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.barplot(x=\"title\", y=\"rating\", data=no_of_ratings_per_movie[:15], ax=axes)\n",
        "for p in axes.patches:\n",
        "    axes.annotate('{}'.format(int(p.get_height())), (p.get_x(), p.get_height()+100))\n",
        "\n",
        "axes.set_yticklabels([ChangingLabelsInK(num) for num in axes.get_yticks()])\n",
        "#custom label in K for thousands using changinglabelsinK function for all numbers in the axes(y_ticks).\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Number of ratings for Top 15 Movies\", fontsize = 20)\n",
        "plt.xlabel(\"Movie\", fontsize = 15)\n",
        "plt.xticks(rotation=70, fontsize=10)\n",
        "plt.ylabel(\"Counts\", fontsize = 15)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAfTF5Aq2SxR"
      },
      "outputs": [],
      "source": [
        "# Calculating average ratings for movies\n",
        "\n",
        "avg_ratings_per_movie = Train_Data.groupby(by = [\"movieId\", \"title\"], as_index=False)[\"rating\"].mean()\n",
        "#average rating per movie\n",
        "avg_ratings_per_movie = avg_ratings_per_movie.reset_index(drop=True)\n",
        "\n",
        "avg_ratings_per_movie = avg_ratings_per_movie.merge(no_of_ratings_per_movie[[\"movieId\", \"rating\"]], how=\"left\", on=\"movieId\")\n",
        "#merge avg_ratings_per_movie with no_of_ratings_per_movie on movie_id -> we re left with movieId,rating, avg_ratings_per_movie\n",
        "\n",
        "avg_ratings_per_movie.rename(columns={\"rating_x\":\"avg_rating\", \"rating_y\": \"num_of_rating\"}, inplace=True)\n",
        "avg_ratings_per_movie = avg_ratings_per_movie.sort_values(\"num_of_rating\", ascending=False)\n",
        "#sort the movies in descending with the max average at the top row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5jsP56AzMw4"
      },
      "outputs": [],
      "source": [
        "# Visualizing the average ratings by individual Days of the Week\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 1, figsize=(25, 5), sharey=True)\n",
        "\n",
        "sns.barplot(x=\"title\", y=\"avg_rating\", data=avg_ratings_per_movie[:15], ax=axes)\n",
        "\n",
        "for p in axes.patches:\n",
        "    axes.annotate('{}'.format(round(p.get_height(), 2)), (p.get_x()+0.3, p.get_height()))\n",
        "\n",
        "plt.tick_params(labelsize = 15)\n",
        "plt.title(\"Average Ratings For top 15 movies\", fontsize = 20)\n",
        "plt.xlabel(\"Top 15 Movie\", fontsize = 15)\n",
        "plt.xticks(rotation=70, fontsize=10)\n",
        "plt.ylabel(\"Rating\", fontsize = 15)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zDuxiRoyxUW"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The cult movies form 1990s have been rated the most.\n",
        "2. Pulp Fiction, Forrest Gump, Shawshank Redemption and Silience of the Lambs have been rated over 50K times.\n",
        "3. Shawshank Redemption has the highest average rating of 4.56 based on 50K+ ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZeqBC_45PaJ"
      },
      "outputs": [],
      "source": [
        "# Plotting the PDF and CDF for Avg. rating by Movies\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(25, 5))\n",
        "fig.suptitle(\"Avg Ratings per Movie\", fontsize=25)\n",
        "\n",
        "sns.distplot(avg_ratings_per_movie[\"avg_rating\"], hist = False, ax = axes[0], label = \"PDF\")\n",
        "#deprecated function that can plot both histograms and kde plots\n",
        "axes[0].set_title(\"PDF\", fontsize = 18)\n",
        "axes[0].set_xlabel(\"Average Ratings by Movie\", fontsize = 18)\n",
        "axes[0].tick_params(labelsize = 15)\n",
        "\n",
        "sns.kdeplot(avg_ratings_per_movie[\"avg_rating\"], cumulative = True, ax = axes[1], shade=True, label = \"CDF\")\n",
        "#can plot for continuous or cumulative\n",
        "axes[1].set_title(\"CDF\", fontsize = 18)\n",
        "axes[1].set_xlabel(\"Average Ratings by Movie\", fontsize = 18)\n",
        "axes[1].tick_params(labelsize = 15)\n",
        "\n",
        "fig.subplots_adjust(wspace=2)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZk_rpWDBMmt"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The distribution of average rating for movie is fairly normal one.\n",
        "2. The cdf shows that the avg. rating is more frequent after 3.\n",
        "3. Curve peaks around a rating of 3-4, indicating that most movies have an average rating in this range.\n",
        "4. Density at lower ratings (0-1) is low, indicating that very few movies have extremely low average ratings.\n",
        "5. CDF Increases steeply between ratings 2 and 4, indicating that a majority of movies have average ratings within this range.\n",
        "6. Curve flattens near 1 as it approaches an average rating of 5, meaning almost all movies fall within the 2-4 rating range, with very few having an average rating close to 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL0s57q3iQa8"
      },
      "outputs": [],
      "source": [
        "Train_Data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaX3B7524VZ5"
      },
      "source": [
        "### **3.3. Feature Engineering**\n",
        "\n",
        "Now that we have completed the data exploration part, we can start the Feature Engineering in order to prepare the data for the ML algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1b6Nr8ZNZfy"
      },
      "source": [
        "#### **3.3.1 Creating Matrices**\n",
        "\n",
        "We will be creating matrices like: User-Item matrix, User-User and Item-Item similarity matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yvL8KRiNjvy"
      },
      "source": [
        "---\n",
        "\n",
        "#####**1. Creating USER-ITEM sparse matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkTaat0uNi5x"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "startTime = datetime.now()\n",
        "\n",
        "print(\"Creating USER_ITEM sparse matrix for train Data..\")\n",
        "\n",
        "# Check if the sparse matrix file already exists in the current directory\n",
        "if os.path.isfile(\"TrainUISparseData.npz\"):\n",
        "    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n",
        "    TrainUISparseData = sparse.load_npz(\"TrainUISparseData.npz\")\n",
        "    print(\"Shape of Train Sparse matrix = \" + str(TrainUISparseData.shape))\n",
        "else:\n",
        "    print(\"We are creating sparse data..\")\n",
        "\n",
        "    # Assuming Train_Data contains 'rating', 'userId', and 'movieId' columns\n",
        "    TrainUISparseData = sparse.csr_matrix((Train_Data.rating, (Train_Data.userId, Train_Data.movieId)))\n",
        "    #Compressed Sparse Row (CSR) matrix called TrainUISparseData using the scipy.sparse.csr_matrix function.\n",
        "    #This type of sparse matrix is memory-efficient and ideal for storing large, sparse datasets where most of the elements are zero\n",
        "    #Train_Data.userId contains the user IDs, which will be the row indices.\n",
        "\n",
        " # Train_Data.movieId contains the movie IDs, which will be the column indices.\n",
        " # For each entry in Train_Data.rating, there is a corresponding (userId, movieId) pair that specifies where that rating should be placed in the matrix.\n",
        "\n",
        "\n",
        "    print(\"Creation done. Shape of sparse matrix: \", str(TrainUISparseData.shape))\n",
        "    print(\"Saving it into disk for further usage.\")\n",
        "    sparse.save_npz(\"TrainUISparseData.npz\", TrainUISparseData)\n",
        "    print(\"Done\\n\")\n",
        "\n",
        "print(\"Time taken: \", datetime.now() - startTime)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYlQ6kydSI10"
      },
      "outputs": [],
      "source": [
        "rows,cols = TrainUISparseData.shape\n",
        "presentElements = TrainUISparseData.count_nonzero()\n",
        "#equivalent to counting how many user-movie pairs have a rating\n",
        "\n",
        "print(\"Sparsity Of Train matrix : {}% \".format((1-(presentElements/(rows*cols)))*100))\n",
        "#rows*columns->gives the total number of elements\n",
        "#presentElements gives the no of non zero elements (user+movie pair with a rating)\n",
        "#we subtract with 1 to give us the probability of absent elements\n",
        "#sparsity = 1-density\n",
        "#we get the final answer as a percentage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The sparsity value tells us how much of the matrix consists of zeros. In recommendation systems, high sparsity is common because most users rate only a small subset of all available movies. Calculating sparsity is useful to understand the dataset’s characteristics and to optimize memory usage and computational efficiency.**"
      ],
      "metadata": {
        "id": "jNa2rqOIbchN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGRaA1zRsde-"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "startTime = datetime.now()\n",
        "\n",
        "print(\"Creating USER_ITEM sparse matrix for test Data..\")\n",
        "\n",
        "# Check if the sparse matrix file already exists in the current directory\n",
        "if os.path.isfile(\"TestUISparseData.npz\"):\n",
        "    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n",
        "    TestUISparseData = sparse.load_npz(\"TestUISparseData.npz\")\n",
        "    print(\"Shape of Test Sparse Matrix: \", str(TestUISparseData.shape))\n",
        "else:\n",
        "    print(\"We are creating sparse data..\")\n",
        "    # Assuming Test_Data contains 'rating', 'userId', and 'movieId' columns\n",
        "    TestUISparseData = sparse.csr_matrix((Test_Data.rating, (Test_Data.userId, Test_Data.movieId)))\n",
        "    #a matrix with users as rows, movies as columns, and the values that fill in the boxes being the rating given to the movies\n",
        "    print(\"Creation done. Shape of sparse matrix: \", str(TestUISparseData.shape))\n",
        "    print(\"Saving it into disk for further usage.\")\n",
        "    sparse.save_npz(\"TestUISparseData.npz\", TestUISparseData)\n",
        "    print(\"Done\\n\")\n",
        "\n",
        "print(\"Time Taken: \", datetime.now() - startTime)\n",
        "\n",
        "#a user-item (user-movie) matrix where each cell shows the rating given by a user to a movie, with unfilled cells representing unrated items.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gsd1K3RSSsM"
      },
      "outputs": [],
      "source": [
        "rows,cols = TestUISparseData.shape\n",
        "presentElements = TestUISparseData.count_nonzero()\n",
        "\n",
        "print(\"Sparsity Of Test matrix : {}% \".format((1-(presentElements/(rows*cols)))*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX9ehvPFR-D8"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. Shape of sparse matrix depends on highest value of userId and highest value of movieId.\n",
        "2. In the test set, there are few users from train set which are not present in the test set.\n",
        "3. For the movieId, there are less movies in the train set as compared to test set. The reason stems from the fact that we split the data based on time, and newer movies would have fallen into test set.\n",
        "4. The sparsity of train set is 99.19% while the sparsity of test set is 99.89%.\n",
        "\n",
        "Users in the Test Set:\n",
        "\n",
        "    There are fewer users in the test set than in the train set, and some users from the train set may not appear in the test set. This is common in train-test splits where certain users might only have ratings in the training data but not in the test data, which can affect the model's performance on unseen users.\n",
        "\n",
        "Movies in the Test Set:\n",
        "\n",
        "    There are fewer movies in the train set than in the test set. This is likely because the data split was based on time, meaning that newer movies are more likely to appear in the test set. This observation implies that movies added later are included in the test set but may not be present in the training data, which can pose challenges for models predicting ratings for new movies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNYQe-1oN5ne"
      },
      "outputs": [],
      "source": [
        "# Function to Calculate Average rating for users or movies from User-movie sparse matrix\n",
        "\n",
        "def getAverageRatings(sparseMatrix, if_user):\n",
        "\n",
        "    #axis = 1 means rows and axis = 0 means columns\n",
        "    ax = 1 if if_user else 0\n",
        "    #the axis would be a row if the value is of a user\n",
        "\n",
        "    sumOfRatings = sparseMatrix.sum(axis = ax).A1 #summation along a row or column, convert to a 1D array\n",
        "    noOfRatings = (sparseMatrix!=0).sum(axis = ax).A1\n",
        "#     (sparseMatrix != 0): Creates a boolean matrix where each cell is True if the rating is non-zero and False otherwise.\n",
        "# .sum(axis=ax): Sums the True values along the specified axis, which counts the number of non-zero ratings for each user or movie.\n",
        "# .A1: Converts the result to a flat 1D array format, so each element represents the count of ratings for one user or movie.\n",
        "\n",
        "    rows, cols = sparseMatrix.shape\n",
        "    #returns the no of users and and the no of movies.\n",
        "\n",
        "    averageRatings = {i: sumOfRatings[i]/noOfRatings[i] for i in range(rows if if_user else cols) if noOfRatings[i]!=0}\n",
        "    # Calculate average ratings, avoiding division by zero\n",
        "    #calculates the average of ratings for each i where i either belongs to users if (\"1\") else movies (cols)(0)\n",
        "    #his is a dictionary comprehension that creates a dictionary with keys as user IDs (if if_user=True) or movie IDs (if if_user=False) and\n",
        "    #values as their average ratings.\n",
        "    #i is the key and the avg(sumofratings/noofratings) is the average_rating for users or movies\n",
        "\n",
        "    return averageRatings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tQIVIAXN5uZ"
      },
      "outputs": [],
      "source": [
        "AvgRatingUser = getAverageRatings(TrainUISparseData, True) #corresponding to if_user\n",
        "AvgRatingMovie = getAverageRatings(TrainUISparseData, False)\n",
        "train_users = len(AvgRatingUser)\n",
        "uncommonUsers = total_users - train_users\n",
        "\n",
        "print(\"Total no. of Users : \", total_users)\n",
        "print(\"No. of Users in Train data : \", train_users)\n",
        "print(\"No. of Users not present in Train data : {}({}%)\".format(uncommonUsers, np.round((uncommonUsers/total_users)*100), 2))\n",
        "#calculate the percentage of absent_users and round of the percentage to two decimal places.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLbmfladXog0"
      },
      "outputs": [],
      "source": [
        "train_movies = len(AvgRatingMovie)\n",
        "uncommonMovies = total_movies - train_movies\n",
        "\n",
        "print(\"Total no. of Movies : \", total_movies)\n",
        "print(\"No. of Movies in Train data : \", train_movies)\n",
        "print(\"No. of Movies not present in Train data = {}({}%)\".format(uncommonMovies, np.round((uncommonMovies/total_movies)*100), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raOq33hoYSyq"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. Recommendation System suffers from Cold Start problems, which needs to be tackled wisely in order to design a effective system.\n",
        "2. There are 26027, ie 19% of the users are not present in the training data.\n",
        "3. There are 12387, ie 54% of the movies which are not present in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **“cold start problem”** is a common challenge that occurs in recommender systems. It refers to a situation where a system or algorithm runs into difficulties when it has little or no historical data about a user or an item. Obviously, this makes it challenging to provide relevant personalized recommendations.  \n",
        "\n",
        "In the context of recommender systems, there are two main types of cold start problems — user cold start and item cold start.  \n",
        "\n",
        "**User cold start:** When a user first becomes part of a recommender system, the system has limited information about their preferences and behavior. This makes it difficult to provide personalized recommendations. In such cases, the system may rely on generic recommendations or ask the user to provide explicit feedback, such as ratings or preferences, to build a user profile.\n",
        "\n",
        "**Item cold start:** New items, such as products or content, may not have accumulated enough user interactions or ratings to generate accurate recommendations. As a result, the system may struggle to recommend these new items effectively to the users in the system. Sometimes, collaborative filtering methods that rely on user-item interactions may not work well for item cold start problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "stYl3adHPJF-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j7TcFjFmRwy"
      },
      "source": [
        "---\n",
        "\n",
        "#####**2. Creating Similarity Matrix**\n",
        "\n",
        "Computation of user-user or item-item similarity matrix is impossible if computational power is limited given we have a user vector of size 112K. There will be a matrix of size 14K x 14K.\n",
        "\n",
        "On the other hand, if we try to reduce the dimension say by truncated SVD then it would take even more time because truncated SVD creates dense matrix and amount of multiplication for creation of user-user similarity matrix would increase dramatically.\n",
        "\n",
        "For the workaround, we will maintain a binary Vector for users, which tells us whether we already computed similarity for this user or not or compute top (let's just say, 1000) most similar users for this given user, and add this to our datastructure, so that we can just access it(similar users) without recomputing it again.\n",
        "\n",
        "If it is already computed, just get it directly from our datastructure, which has that information. In production time, We might have to recompute similarities, if it is computed a long time ago. Because user preferences changes over time. If we could maintain some kind of Timer, which when expires, we have to update it ( recompute it ).\n",
        "\n",
        "The datastructure to be used is purely implementation dependant.One simple method is to maintain a Dictionary Of Dictionaries:\n",
        "  - key : userid\n",
        "  - value : Again a dictionary\n",
        "       - key : _Similar User\n",
        "       - value: Similarity Value>\n",
        "\n",
        "Key: The outer dictionary’s key is the user_id for whom we are storing similarities.\n",
        "\n",
        "Value: The value is another dictionary where:\n",
        "\n",
        "  The inner dictionary’s keys are IDs of the similar users.\n",
        "  The inner dictionary’s values are similarity scores between the user_id and each of its most similar users.\n",
        "\n",
        "This structure is efficient because:\n",
        "\n",
        "  You only store similarities for the top 1,000 users per user, which limits memory usage.\n",
        "  Retrieving the top similar users for a given user is quick and easy since it’s just a lookup in the dictionary.\n",
        "\n",
        "\n",
        "  Each time you retrieve similarity data, check if the timer has expired.\n",
        "If it has expired (indicating the similarity scores might be outdated), recompute the similarity scores and update the similarity_data dictionary with the new values.\n",
        "Reset the timer for the next check.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZMNstbtlQ53"
      },
      "source": [
        "---\n",
        "\n",
        "**2.1. Computing Item-Item Similarity Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbdipwGqlYsd"
      },
      "outputs": [],
      "source": [
        "# Computing user-user similarity matrix for the train data\n",
        "# We have 138K sized sparse vectors using which a 14K x 14K movie similarity matrix would be calculated\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "if not os.path.isfile(file_path + \"/m_m_similarity.npz\"):\n",
        "    print(\"Movie-Movie Similarity file does not exist in your disk. Creating Movie-Movie Similarity Matrix...\")\n",
        "    m_m_similarity = cosine_similarity(TrainUISparseData.T, dense_output = False)\n",
        "    #Here, cosine_similarity is used to calculate the similarity between movies based on their ratings by users.\n",
        "    #here, the rows are movies, the columns being users.\n",
        "\n",
        "    print(\"Dimension of Matrix : \", m_m_similarity.shape)\n",
        "    print(\"Storing the Movie Similarity matrix on disk for further usage\")\n",
        "    sparse.save_npz(file_path + \"/m_m_similarity.npz\", m_m_similarity)\n",
        "else:\n",
        "    print(\"File exists in the disk. Loading the file...\")\n",
        "    m_m_similarity = sparse.load_npz(file_path + \"/m_m_similarity.npz\")\n",
        "    print(\"Dimension of Matrix : \", m_m_similarity.shape)\n",
        "\n",
        "print(\"The time taken to compute movie-movie similarity matrix is : \", datetime.now() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XX21MasR4tG"
      },
      "outputs": [],
      "source": [
        "# Creating a function to take Movie Name and generate the top matched name and generate its N similar movies based on M-M Similary\n",
        "\n",
        "def GetSimilarMoviesUsingMovieMovieSimilarity(movie_name, num_of_similar_movies):\n",
        "    matches = process.extract(movie_name, movie_list_in_training[\"title\"], scorer=fuzz.partial_ratio)\n",
        "    #each element in matches is a tuple containing:->\n",
        "    #The movie title that matches (matches[0][0]),\n",
        "    # The similarity score between movie_name and the matched title (matches[0][1]), and\n",
        "    # The index of the matched movie title in movie_list_in_training (matches[0][2]).\n",
        "\n",
        "  #This line uses fuzzy matching to find the closest matching movie title in the dataset (movie_list_in_training[\"title\"]).\n",
        "  # process.extract() from the fuzzywuzzy library returns a list of possible matches, based on similarity scoring.\n",
        "  # fuzz.partial_ratio allows for partial matching, making it robust even if the user enters only part of the movie title.\n",
        "\n",
        "  # matches will be a list of tuples where each tuple contains:-\n",
        "  #  The matched movie title,\n",
        "  #  The similarity score,\n",
        "  #  The index of the match in movie_list_in_training.\n",
        "    #movies list in training consists of the movie title and 3 other columns.\n",
        "\n",
        "    if len(matches) == 0:\n",
        "        return \"No Match Found\"\n",
        "    movie_id = movie_list_in_training.iloc[matches[0][2]][\"movieId\"]\n",
        "    # get the movie id of the closest match\n",
        "    # matches[0] represents the best match (the first result in the list),\n",
        "    # and matches[0][2] gives the index of this best match in movie_list_in_training.\n",
        "\n",
        "# If matches[0] is (\"The Matrix\", 90, 1234), then matches[0][2] would be 1234.\n",
        "# This index 1234 tells us the row in movie_list_in_training where the best matching movie title is located.\n",
        "\n",
        "    similar_movie_id_list = np.argsort(-m_m_similarity[movie_id].toarray().ravel())[0:num_of_similar_movies+1]\n",
        "    # m_m_similarity[movie_id] retrieves the row corresponding to movie_id. This row contains similarity scores\n",
        "    # between movie_id and every other movie in the matrix.\n",
        "    #the first part gives us the similarity score between that movie and all other movies as a sparse matrix that will get converted to a\n",
        "    # 2d array, .ravel() is used to flatten the dense 2D array into a 1D array. The result is a 1D array where each element\n",
        "    # represents the similarity score between movie_id and each other movie. np argsort() - sorts in ascending order.\n",
        "    # returns all indices in sorted order, but we only need the top num_of_similar_movies similar movies.\n",
        "    # We add 1 here because the movie itself (movie_id) will likely be the most similar (with a similarity score of 1),\n",
        "    # and we may want to include it for reference or exclude it as needed.\n",
        "\n",
        " # -(negative) sign to invert the similarity scores. This is done because we want the most similar movies\n",
        " # (i.e., the highest scores) to come first in the sorted list, and np.argsort sorts in ascending order.\n",
        " #By negating the scores, we ensure that movies with higher similarity scores(hence, more negative)\n",
        " #appear earlier in the sorted array.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    sm_df = movie_list_in_training[movie_list_in_training[\"movieId\"].isin(similar_movie_id_list)]\n",
        "    #sm_df is a dataframe that contains only the movies in similar_movie_id_list\n",
        "    #The outer movie_list_in_training[...] applies this condition to select only rows where the movieId is in similar_movie_id_list.\n",
        "\n",
        "    sm_df[\"order\"] = sm_df.apply(lambda x: list(similar_movie_id_list).index(x[\"movieId\"]), axis=1)\n",
        "    #new column- order- to specify the order of similarity for each movie relative to the target movie.\n",
        "    #sm_df.apply(...) applies a function to each row of sm_df.\n",
        "#     x[\"movieId\"] accesses the movieId of the current row.\n",
        "#     list(similar_movie_id_list).index(x[\"movieId\"]) finds the index of this movieId in similar_movie_id_list.\n",
        "#         This index corresponds to the similarity rank: for example, if movieId = 2 is the most similar movie,\n",
        "#     it will have an index of 0 in similar_movie_id_list.\n",
        "\n",
        "# The result is that each row in sm_df gets an order value based on its similarity rank.\n",
        "# The most similar movie will have order = 0, the next most similar will have order = 1, and so on.\n",
        "\n",
        "    return sm_df.sort_values(\"order\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QTkTz4dHv2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSMtUYbrdBpG"
      },
      "outputs": [],
      "source": [
        "# Picking random movie and checking it's top 10 most similar movies\n",
        "\n",
        "GetSimilarMoviesUsingMovieMovieSimilarity(\"Star Wars\", 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ0chmC-ZLGR"
      },
      "source": [
        "---\n",
        "\n",
        "**2.2. Computing User-User Similarity Matrix.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP-pRQhRsJCY"
      },
      "outputs": [],
      "source": [
        "# Getting highest user id\n",
        "\n",
        "row_index, col_index = TrainUISparseData.nonzero()\n",
        "# row indices of the non-zero elements (i.e., the user IDs for which there is a rating or interaction),\n",
        "# and col_index contains the column indices of the non-zero elements (i.e., the item or movie IDs for which there is a rating).\n",
        "\n",
        "unique_user_id = np.unique(row_index)\n",
        "#returns the unique values in the row_index\n",
        "#np.unique(row_index) returns the unique values in row_index, which represent all the user IDs that have at least one rating or interaction in the dataset.\n",
        "# unique_user_id now holds a sorted array of all distinct user IDs with non-zero ratings.\n",
        "\n",
        "print(\"Max User id is :\", np.max(unique_user_id))\n",
        "#the user with the max no of ratings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U7QV74grsCf"
      },
      "outputs": [],
      "source": [
        "# Here, we are calculating user-user similarity matrix only for first 100 users in our sparse matrix. And we are calculating\n",
        "# Top 100 most similar users with them.\n",
        "#user-user matrix to compute similarities.\n",
        "\n",
        "def getUser_UserSimilarity(sparseMatrix, top = 100):\n",
        "    startTimestamp20 = datetime.now()\n",
        "\n",
        "    row_index, col_index = sparseMatrix.nonzero()\n",
        "    #non zero ratings; fetch the rows and the cols indices of non zero ratings.\n",
        "    rows = np.unique(row_index)\n",
        "    #find all unique users.\n",
        "\n",
        "    similarMatrix = np.zeros(13849300).reshape(138493,100)    # 138493*100 = 13849300. As we are building similarity matrix only\n",
        "    #for top 100 most similar users.\n",
        "    #np.zeros(13849300) creates a 1D array of zeros with 13,849,300 entries.\n",
        "    #.reshape(138493, 100) reshapes it into a 2D array with 138,493 rows and 100 columns.\n",
        "# Here, 138493 could represent the total number of users, and 100 represents the number of top similar users we want to store per user.\n",
        "\n",
        "    timeTaken = []\n",
        "    #time takne for each user's similarity comparision\n",
        "\n",
        "    howManyDone = 0\n",
        "    #counter to track the count of processed users\n",
        "\n",
        "    for row in rows[:top]:\n",
        "      #since we re doing this for a 100 users, extract from top 100 rows\n",
        "        howManyDone += 1\n",
        "        #increment the count by 1 for each user\n",
        "\n",
        "        startTimestamp = datetime.now().timestamp()  #timestamp at the start of a user's computation\n",
        "\n",
        "        sim = cosine_similarity(sparseMatrix.getrow(row), sparseMatrix).ravel()\n",
        "        #calculate the cosine similarity between user (sparsematrix.getrow(row)), adn the total number of users (SparseMatrix)\n",
        "        #ravel will convert this data into a 1d array for better understanding\n",
        "        #If sparseMatrix.getrow(row) is [1, 0, 3] and sparseMatrix has rows like [0, 2, 1] and [1, 0, 3],\n",
        "        #then sim will store similarities between [1, 0, 3] and all other rows.\n",
        "\n",
        "        top100_similar_indices = sim.argsort()[-top:]\n",
        "        #sim.argsort () - returns the indices of the sorted values,\n",
        "        #we want the top 100 indices. so we select the last top 100, it selects the indices after the -100th item (100 items to the end)\n",
        "\n",
        "        top100_similar = sim[top100_similar_indices]\n",
        "        #extract the values from the similarity matrix via their indices\n",
        "        #returns an array with the top 100 similarity scores, arranged in descending order\n",
        "\n",
        "        similarMatrix[row] = top100_similar\n",
        "        #stores the top 100 users in the similiarity matrix that we created earlier.\n",
        "        #13k rows (users) - columns(100 similar users)\n",
        "\n",
        "        timeforOne = datetime.now().timestamp() - startTimestamp #current-start\n",
        "        #we re calculating the total time taken for computation of similarity score for one user\n",
        "        timeTaken.append(timeforOne)\n",
        "        #timeTaken = [0.12, 0.15, 0.10, 0.13, 0.14] #consider 5 users and their respective time taken.\n",
        "\n",
        "        if howManyDone % 20 == 0:\n",
        "            print(\"Time elapsed for {} users = {}sec\".format(howManyDone, (datetime.now() - startTimestamp20)))\n",
        "            #prints the cumulative time taken for every 20 users.\n",
        "\n",
        "    print(\"Average Time taken to compute similarity matrix for 1 user = \"+str(sum(timeTaken)/len(timeTaken))+\"seconds\")\n",
        "    #compute the average time taken for one user\n",
        "\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    #set the style for the sns plot\n",
        "    fig = plt.figure(figsize = (25, 5))\n",
        "    #create a figure object of width 25 length 5\n",
        "\n",
        "    plt.plot(timeTaken, label = 'Time Taken For Each User')\n",
        "    plt.plot(np.cumsum(timeTaken), label='Cumulative Time')\n",
        "    #the array if 2d is first converted to a 1 d(flattened by deafult) and then the sum is calculated along an axis\n",
        "\n",
        "    plt.legend(loc='upper left', fontsize = 15)\n",
        "    plt.xlabel('Users', fontsize = 20)\n",
        "    plt.ylabel('Time(Seconds)', fontsize = 20)\n",
        "    plt.tick_params(labelsize = 15)\n",
        "    plt.show()\n",
        "\n",
        "    return similarMatrix\n",
        "\n",
        "simMatrix = getUser_UserSimilarity(TrainUISparseData, 100)\n",
        "# calls the function with TrainUISparseData (a sparse matrix) as input and stores the result in simMatrix.\n",
        "# This will be the 138,493 x 100 matrix of similarity scores for each of the first 100 users.\n",
        "\n",
        "# {TrainUISparseData = sparse.csr_matrix((Train_Data.rating, (Train_Data.userId, Train_Data.movieId))) -\n",
        "# where the columns are movies_id, and the the rows are the users_id, with the values being the rating given to a movie}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK6TWLZB-c7R"
      },
      "outputs": [],
      "source": [
        "# Calculating user-user similarity only for particular users in our sparse matrix and return user_ids\n",
        "\n",
        "def Calculate_User_User_Similarity(sparseMatrix, user_id, num_of_similar_users=10):\n",
        "  #we ve specified a particular user_id, and given the no_of_similar users we require\n",
        "\n",
        "    if user_id in unique_user_id:\n",
        "        # Calculating the cosine similarity for user_id with all the \"userId\"\n",
        "        #if the user exists in the list of users(unique)\n",
        "\n",
        "        sim = cosine_similarity(sparseMatrix.getrow(user_id), sparseMatrix).ravel()\n",
        "        #calculate the cosine similarity between the given_user and all the other users(all other rows) and then convert into a ONE D array\n",
        "        # Sorting the indexs(user_id) based on the similarity score for all the user ids\n",
        "        #If sim = [1.0, 0.8, 0.2, 0.9], this means:\n",
        "        # The similarity score with User 0 is 1.0, with User 1 is 0.8, with User 2 is 0.2, and with User 3 is 0.9.\n",
        "\n",
        "        top_similar_user_ids = sim.argsort()[::-1]\n",
        "        # Sorted the similarity values in descending order starting from the last and return their indices, not the values.\n",
        "\n",
        "        top_similarity_values = sim[top_similar_user_ids]\n",
        "        #get the similarity values from the indices\n",
        "\n",
        "    return top_similar_user_ids[1: num_of_similar_users+1]\n",
        "    #returns the top similar user ids from 1 to n+1 (skipping the first entry [0] - because that would be the user themself)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7ZvajxRZOFe"
      },
      "outputs": [],
      "source": [
        "# Getting top 5 users similar to userId: 1\n",
        "\n",
        "#Calculate_User_User_Similarity(sparseMatrix, user_id, num_of_similar_users):\n",
        "similar_users_1 = Calculate_User_User_Similarity(TrainUISparseData, 1, 5)\n",
        "similar_users_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU01nw0IG9wP"
      },
      "source": [
        "---\n",
        "\n",
        "#### **3.3.2 Feature Extraction**\n",
        "\n",
        "Now we can start extracting meaningful features in order to prepare the data for ML algorithms."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HgWTKhPn7D3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G5N7nCJDyWH"
      },
      "outputs": [],
      "source": [
        "# Path for saving/loading files\n",
        "\n",
        "file_path = \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSGx8rcl5Skk"
      },
      "outputs": [],
      "source": [
        "# Since the given dataset might not completely fit into computaton capacity that we have, we will sample the data and work it\n",
        "\n",
        "# Function for Sampling random movies and users to reduce the size of rating matrix\n",
        "def get_sample_sparse_matrix(sparseMatrix, n_users, n_movies, matrix_name):\n",
        "\n",
        "    np.random.seed(15)   #this will give same random number everytime, without replacement\n",
        "    startTime = datetime.now()\n",
        "\n",
        "    users, movies, ratings = sparse.find(sparseMatrix)\n",
        "    #sparse.find(sparseMatrix) is a method that returns the indices and values of the non-zero elements in a sparse matrix.\n",
        "    #In the case of a user-item ratings matrix, these are the cells where a user has rated a movie.\n",
        "    # returns the rows for every non-zero rating. if there are two non zero ratings in the first row, we get 0,0 and so forth\n",
        "    #similarly for every column\n",
        "    #ratings - returns the actual non zero values of ratings of each cell.\n",
        "\n",
        "    uniq_users = np.unique(users)\n",
        "    #returns the indices of all unique users\n",
        "    uniq_movies = np.unique(movies)\n",
        "    #returns the indices of all unique movies\n",
        "\n",
        "    userS = np.random.choice(uniq_users, n_users, replace = False)\n",
        "    #randomly sample the population into a sample, with no replacement into n users, n_movies, in one sample from unique_users.\n",
        "\n",
        "    movieS = np.random.choice(uniq_movies, n_movies, replace = False)\n",
        "    #similarly for movies\n",
        "\n",
        "    mask = np.logical_and(np.isin(users, userS), np.isin(movies, movieS))\n",
        "    # A mask is created to select only the ratings that correspond to the sampled users and\n",
        "    # movies using np.isin to check whether each user and movie is in the sampled list\n",
        "    # checks each user index in the users array to see if it is in the userS array (the randomly selected subset of users).\n",
        "    # the result is boolean array of the same length as users\n",
        "    # returns a boolean array where each element is True only\n",
        "    # if the corresponding elements in both input arrays are True. Otherwise, it will be False\n",
        "    # only the ratings where both the user and movie are in the sampled sets are marked as True.\n",
        "    # This mask will then be used to filter the ratings to build the smaller sampled sparse matrix.\n",
        "\n",
        "    sparse_sample = sparse.csr_matrix((ratings[mask], (users[mask], movies[mask])), shape = (max(userS)+1, max(movieS)+1))\n",
        "    #create a Compressed Sparse Row (CSR) format matrix with values of ratings(As tuples) from the sample, are stored in a single box, indexed by the\n",
        "    # row(user) and column(movie) no. from the sample. its shape is the largest user index (max number of users) + 1\n",
        "    # because the indexing starts from 0. therefore max(5) would be 0,1,2,3,4,5 - 6 users. similarly, for the movies as well.\n",
        "\n",
        "    print(\"Sparse Matrix creation done. Saving it for later use.\")\n",
        "    sparse.save_npz(file_path + \"/\" + matrix_name, sparse_sample)\n",
        "    print(\"Shape of Sparse Sampled Matrix = \" + str(sparse_sample.shape))\n",
        "    print(\"Time taken : \", datetime.now() - startTime)\n",
        "\n",
        "    return sparse_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vr783V36k38"
      },
      "outputs": [],
      "source": [
        "# Creating Sample Sparse Matrix for Train Data\n",
        "\n",
        "if not os.path.isfile(file_path + \"/TrainUISparseData_Sample.npz\"):\n",
        "    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n",
        "    train_sample_sparse = get_sample_sparse_matrix(TrainUISparseData, 5000, 1000, \"TrainUISparseData_Sample.npz\")\n",
        "    #get_sample_sparse_matrix(sparseMatrix, n_users, n_movies, matrix_name):\n",
        "\n",
        "else:\n",
        "    print(\"File is already present in the disk. Loading the file...\")\n",
        "    train_sample_sparse = sparse.load_npz(file_path + \"/TrainUISparseData_Sample.npz\")\n",
        "    print(\"Shape of Train Sample Sparse Matrix = \" + str(train_sample_sparse.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbRxDP937UqG"
      },
      "outputs": [],
      "source": [
        "# Creating Sample Sparse Matrix for Test Data\n",
        "\n",
        "if not os.path.isfile(file_path + \"/TestUISparseData_Sample.npz\"):\n",
        "    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n",
        "    test_sample_sparse = get_sample_sparse_matrix(TestUISparseData, 2000, 200, \"TestUISparseData_Sample.npz\")\n",
        "else:\n",
        "    print(\"File is already present in the disk. Loading the file...\")\n",
        "    test_sample_sparse = sparse.load_npz(file_path + \"/TestUISparseData_Sample.npz\")\n",
        "    print(\"Shape of Test Sample Sparse Matrix = \" + str(test_sample_sparse.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmG6YmgYFflc"
      },
      "outputs": [],
      "source": [
        "# Checking the shape of Training and test data\n",
        "\n",
        "print(\"Shape of Train Sparse Matrix : \", train_sample_sparse.shape)\n",
        "print(\"Shape of Test Sparse Matrix : \", test_sample_sparse.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkRx0mYhJjcT"
      },
      "outputs": [],
      "source": [
        "# Calculating few GlobalAverageRating, AvgMovieRating, AvgUserRating and TotalNoOfRatings\n",
        "\n",
        "globalAvgRating = np.round((train_sample_sparse.sum()/train_sample_sparse.count_nonzero()), 2)\n",
        "#getAverageRatings(sparseMatrix, if_user)\n",
        "globalAvgMovies = getAverageRatings(train_sample_sparse, False)\n",
        "globalAvgUsers = getAverageRatings(train_sample_sparse, True)\n",
        "print(\"Global average of all movies ratings in Train Set is : \", globalAvgRating)\n",
        "print(\"No. of ratings in the train matrix is : \", train_sample_sparse.count_nonzero())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j22PzgfHJkSD"
      },
      "outputs": [],
      "source": [
        "# Function to extract features and create row using the sparse matrix\n",
        "\n",
        "def CreateFeaturesForTrainData(SampledSparseData, TrainSampledSparseData):\n",
        "#trying to create features for the training data\n",
        "    startTime = datetime.now()\n",
        "\n",
        "    # Extracting userId list, movieId list and Ratings that are non zero\n",
        "    sample_users, sample_movies, sample_ratings = sparse.find(SampledSparseData)\n",
        "\n",
        "    print(\"No. of rows in the returned dataset : \", len(sample_ratings))\n",
        "    #return count of ratings\n",
        "\n",
        "    count = 0\n",
        "    data = []\n",
        "    #data will store each generated feature row for all user-movie-rating triplets\n",
        "\n",
        "    for user, movie, rating in zip(sample_users, sample_movies, sample_ratings):\n",
        "      #creating a single tuple from users, movies, ratings - a triplet\n",
        "\n",
        "        row = list()\n",
        "        #a new row list to store all features for the current triplet.\n",
        "\n",
        "#----------------------------------Appending \"user Id\" average, \"movie Id\" average & global average rating-----------#\n",
        "        row.append(user)\n",
        "        row.append(movie)\n",
        "        row.append(globalAvgRating)\n",
        "\n",
        "#----------------------------------Appending \"user\" average, \"movie\" average & rating of \"user\"\"movie\"-----------#\n",
        "        try:\n",
        "            row.append(globalAvgUsers[user])\n",
        "        except (KeyError):\n",
        "            global_average_rating = globalAvgRating\n",
        "            row.append(global_average_rating)\n",
        "            #The user's average rating (globalAvgUsers[user]) is appended if it exists; otherwise,\n",
        "            #the global average rating is used (to handle cases where there is no prior rating data for that user).\n",
        "        except:\n",
        "            raise\n",
        "        try:\n",
        "            row.append(globalAvgMovies[movie])\n",
        "            #trying to append the average rrating of the movie\n",
        "        except (KeyError):\n",
        "            global_average_rating = globalAvgRating\n",
        "            #append a general global avg in case no prior rating exists\n",
        "            row.append(global_average_rating)\n",
        "        except:\n",
        "            raise\n",
        "\n",
        "#----------------------------------Ratings given to \"movie\" by top 5 similar users with \"user\"--------------------#\n",
        "        try:\n",
        "            similar_users = cosine_similarity(TrainSampledSparseData[user], TrainSampledSparseData).ravel()\n",
        "            #each user’s rating pattern, to indicate how alike they are. The result is a flattened (1D) array similar_users\n",
        "            #where each value shows how similar each user is to the specified user.\n",
        "\n",
        "            similar_users_indices = np.argsort(-similar_users)[1:]\n",
        "            #a list containing the indices of all similar users arranged in descending order, by negating the values -\n",
        "            #excludes the first, since it's the given user themselves\n",
        "\n",
        "            similar_users_ratings = TrainSampledSparseData[similar_users_indices, movie].toarray().ravel()\n",
        "            #tracts the ratings given by these most similar users to the specified movie, converting the results to a 1D array.\n",
        "            #The similar_users_indices array helps select the rows (users) from the sparse matrix, and movie specifies the column (movie) being targeted.\n",
        "\n",
        "            top_similar_user_ratings = list(similar_users_ratings[similar_users_ratings != 0][:5])\n",
        "            #creates a list of the top 5 similar user ratings given to a particular movie, where the rating is not zero for a movie\n",
        "\n",
        "            top_similar_user_ratings.extend([globalAvgMovies[movie]]*(5-len(top_similar_user_ratings)))\n",
        "            #extends adds each iterable object to the list unlike appends which adds as a single object\n",
        "            #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"movie\" average\n",
        "            #rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"movie\" average rating.\n",
        "\n",
        "            #[globalAvgMovies[movie]] * (5 - len(top_similar_user_ratings)) creates a list that repeats the movie’s average\n",
        "            #rating (globalAvgMovies[movie]) as many times as needed to make up the five total entries.\n",
        "\n",
        "            row.extend(top_similar_user_ratings)\n",
        "            #adds the five values in one step, without having to append five values separately.\n",
        "\n",
        "        #########Cold Start Problem, for a new user or a new movie#########\n",
        "        except (IndexError, KeyError):\n",
        "            global_average_rating = [globalAvgRating]*5\n",
        "            row.extend(global_average_rating)\n",
        "            #f there’s an IndexError or KeyError, it means there was insufficient data for similar users or the movie itself, such as in a cold-start situation (e.g., a new user or new movie).\n",
        "            #In this case, the function adds a list of five global average ratings to the feature row as a fallback.\n",
        "\n",
        "        except:\n",
        "            raise\n",
        "\n",
        "#----------------------------------Ratings given by \"user\" to top 5 similar movies with \"movie\"------------------#\n",
        "        try:\n",
        "            similar_movies = cosine_similarity(TrainSampledSparseData[:,movie].T, TrainSampledSparseData.T).ravel()\n",
        "            #columns to rows and then convert to a 1D array\n",
        "            #selects all users’ ratings for the specified movie and turns the column vector to a row vector and\n",
        "            #then finds similarity between the specified movie and all the movies in the matrix\n",
        "\n",
        "            similar_movies_indices = np.argsort(-similar_movies)[1:]\n",
        "            # sorts the indices of the similar movie list in descending order excluding the movie itself.\n",
        "\n",
        "            similar_movies_ratings = TrainSampledSparseData[user, similar_movies_indices].toarray().ravel()\n",
        "            #extracts the similar movies' ratings for a given user, converts to a oneD array\n",
        "            #collects the ratings that the specified user (user) gave to the top similar movies.\n",
        "\n",
        "             # Before .ravel(): similar_movies_ratings = [[4, 0, 5]]  # shape: (1, 3), a 2D array\n",
        "             # After .ravel() : similar_movies_ratings = [4, 0, 5]  # shape: (3,), a 1D array\n",
        "\n",
        "            top_similar_movie_ratings = list(similar_movies_ratings[similar_movies_ratings != 0][:5])\n",
        "            # creates a list of top 5 similar non-zero movie ratings.\n",
        "\n",
        "            top_similar_movie_ratings.extend([globalAvgUsers[user]]*(5-len(top_similar_movie_ratings)))\n",
        "            #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"user\" average\n",
        "            #rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"user\" average rating.\n",
        "\n",
        "            row.extend(top_similar_movie_ratings)\n",
        "        ########Cold Start Problem, for a new user or a new movie#########\n",
        "        except (IndexError, KeyError):\n",
        "            global_average_rating = [globalAvgRating] * 5 #add the same value of global average rating 5 times\n",
        "            row.extend(global_average_rating)\n",
        "        except:\n",
        "            raise\n",
        "\n",
        "#----------------------------------Appending rating of \"user\"\"movie\"-----------#\n",
        "        row.append(rating)\n",
        "        #pends the actual rating value (rating) from the (user, movie, rating) triplet to row.\n",
        "        #This rating represents the target variable or label in a supervised learning context,\n",
        "        #which the model aims to predict using the features in row\n",
        "\n",
        "        count += 1\n",
        "\n",
        "        data.append(row)\n",
        "\n",
        "        if count % 5000 == 0:\n",
        "            print(\"Done for {}. Time elapsed: {}\".format(count, (datetime.now() - startTime)))\n",
        "\n",
        "    print(\"Total Time for {} rows = {}\".format(len(data), (datetime.now() - startTime)))\n",
        "    print(\"Completed..\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-iqU5rnJkaN"
      },
      "outputs": [],
      "source": [
        "# Using sampled train data, creating Features for each row and saving it into the list\n",
        "\n",
        "data_rows = CreateFeaturesForTrainData(train_sample_sparse, train_sample_sparse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz2rH6xlKiLq"
      },
      "outputs": [],
      "source": [
        "# Using sampled train data, creating Features for each row and saving it into the list\n",
        "\n",
        "test_data_rows = CreateFeaturesForTrainData(test_sample_sparse, train_sample_sparse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhkUkr3JJkge"
      },
      "outputs": [],
      "source": [
        "# Creating the pandas dataframe from the data rows extracted from the sparse matrix for train and test set\n",
        "\n",
        "names = [\"User_ID\", \"Movie_ID\", \"Global_Average\", \"User_Average\", \"Movie_Average\", \"SUR1\", \"SUR2\", \"SUR3\", \"SUR4\", \"SUR5\", \"SMR1\", \"SMR2\", \"SMR3\", \"SMR4\", \"SMR5\", \"Rating\"]\n",
        "train_regression_data = pd.DataFrame(data_rows, columns=names)\n",
        "test_regression_data = pd.DataFrame(test_data_rows, columns=names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M5a-6l8axjV"
      },
      "outputs": [],
      "source": [
        "# Saving the df to drive for future use\n",
        "file_path = \"/content\"\n",
        "train_regression_data.to_csv(file_path + \"/Training_Data_For_Regression.csv\")\n",
        "test_regression_data.to_csv(file_path + \"/Testing_Data_For_Regression.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SjPHonmZ-p7"
      },
      "outputs": [],
      "source": [
        "# Loading the train and test csv files\n",
        "\n",
        "# Path for saving/loading files\n",
        "file_path = \"/content\"\n",
        "\n",
        "print(\"File is already present in the disk. Loading the file...\")\n",
        "\n",
        "train_regression_data = pd.read_csv(file_path + \"/Training_Data_For_Regression.csv\")\n",
        "train_regression_data = train_regression_data.drop([\"Unnamed: 0\"], axis=1)\n",
        "\n",
        "test_regression_data = pd.read_csv(file_path + \"/Testing_Data_For_Regression.csv\")\n",
        "test_regression_data = test_regression_data.drop([\"Unnamed: 0\"], axis=1)\n",
        "\n",
        "print(\"Done..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61MgFPw_nz9l"
      },
      "outputs": [],
      "source": [
        "# Checking the shape and first few records for train data\n",
        "\n",
        "print(\"The shape of the dataframe is : \", train_regression_data.shape)\n",
        "print(\"Number of missing Values : \", train_regression_data.isnull().sum().sum())\n",
        "train_regression_data.head()\n",
        "\n",
        "#User_ID: The unique identifier for each user. This represents the ID of the user who rated a particular movie.\n",
        "\n",
        "# Movie_ID: The unique identifier for each movie. This indicates which movie was rated by the user.\n",
        "\n",
        "# Global_Average: The overall average rating across all users and movies. This serves as a baseline rating in the dataset.\n",
        "\n",
        "# User_Average: The average rating given by a specific user across all movies they have rated. It helps capture a user’s general rating tendency (i.e., whether they tend to rate movies higher or lower on average).\n",
        "\n",
        "# Movie_Average: The average rating received by a specific movie across all users who have rated it. This feature captures the general popularity or quality perception of the movie.\n",
        "\n",
        "# SUR1 to SUR5 (Similar User Ratings): These columns represent ratings of the target movie by the top five users who are most similar to the target user, based on cosine similarity. If fewer than five similar users rated the movie, any missing values are filled with the Movie_Average.\n",
        "\n",
        "# SMR1 to SMR5 (Similar Movie Ratings): These columns represent ratings given by the target user to the top five movies most similar to the target movie (again based on cosine similarity). If fewer than five similar movies have been rated, the User_Average fills in the missing values.\n",
        "\n",
        "# Rating: The actual rating given by the User_ID for the Movie_ID in this row. This is the target variable in a supervised learning context, used to train or evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6ElF5RBYGPz"
      },
      "outputs": [],
      "source": [
        "# Checking the shape and first few records for test data\n",
        "\n",
        "print(\"The shape of the dataframe is : \", test_regression_data.shape)\n",
        "print(\"Number of missing Values : \", test_regression_data.isnull().sum().sum())\n",
        "test_regression_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-_BUSfUD6Mn"
      },
      "source": [
        "Observations:\n",
        "\n",
        "The description of the features are stated below:\n",
        "1. User_ID: ID of a this User\n",
        "2. Movie_ID: ID of a this Movie\n",
        "3. Global_Average: Global Average Rating\n",
        "4. User_Average: Average Rating of this User\n",
        "5. Movie_Average: Average Rating of this Movie\n",
        "6. Ratings given to this Movie by top 5 similar users with this User: (SUR1, SUR2, SUR3, SUR4, SUR5)\n",
        "11. Ratings given by this User to top 5 similar movies with this Movie: (SMR1, SMR2, SMR3, SMR4, SMR5)\n",
        "16. Rating: Rating given by this User to this Movie\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sguxPPpXYsUQ"
      },
      "source": [
        "**Transforming Data for Surprise Models**\n",
        "\n",
        "Transforming Train Data:\n",
        "\n",
        "We can't give raw data (movie, user, rating) to train the model in Surprise library. They have a separate format for TRAIN and TEST data, which will be useful for training the models like SVD, KNN, BaseLineOnly, etc.., in Surprise.\n",
        "\n",
        "\n",
        "Transforming Test Data:\n",
        "\n",
        "For test data we just have to define a tuple (user, item, rating).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn1md9XVn0Fi"
      },
      "outputs": [],
      "source": [
        "train_regression_data[['User_ID', 'Movie_ID', 'Rating']].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpmLRuObn0Nf"
      },
      "outputs": [],
      "source": [
        "# Using Surprise library Data Structures to store train data\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "#Reader class from Surprise specifies the rating scale of the dataset. Here, the ratings range from 1 to 5,\n",
        "#meaning users rated movies on this scale.\n",
        "\n",
        "data = Dataset.load_from_df(train_regression_data[[\"User_ID\", \"Movie_ID\", \"Rating\"]], reader)\n",
        "#Reader object reader ensures that Surprise correctly interprets the rating scale.\n",
        "\n",
        "trainset = data.build_full_trainset()\n",
        "#constructs the entire training dataset for Surprise to use. It transforms the data into a specific Trainset format, which Surprise's algorithms use for training.\n",
        "# trainset now contains all interactions between users and movies, along with each associated rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27vN25cNn0Vw"
      },
      "outputs": [],
      "source": [
        "# Creating tuple for test set\n",
        "#[(user_id_1, movie_id_1, actual_rating_1), (user_id_2, movie_id_2, actual_rating_2), ...]\n",
        "testset = list(zip(test_regression_data[\"User_ID\"].values, test_regression_data[\"Movie_ID\"].values, test_regression_data[\"Rating\"].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93fagKfprG8u"
      },
      "source": [
        "---\n",
        "\n",
        "## **4. Model Buliding**\n",
        "\n",
        "We will try to build a regression model to predict the rating given by an user to a movie based on the generated fetures.\n",
        "\n",
        "We have two Error Metrics:\n",
        "\n",
        "  - RMSE: Root Mean Square Error: RMSE is the error of each point which is squared. Then mean is calculated. Finally root of that mean is taken as final value.\n",
        "\n",
        "  - MAPE: Mean Absolute Percentage Error: The mean absolute percentage error (MAPE), also known as mean absolute percentage deviation (MAPD), is a measure of prediction accuracy of a forecasting method.\n",
        "\n",
        "    The difference between At and Ft is divided by the actual value At again. The absolute value in this calculation is summed for every forecasted point in time and divided by the number of fitted points n. Multiplying by 100% makes it a percentage error.\n",
        "\n",
        "    where At is the actual value and Ft is the forecast value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3qGx_WleJvP"
      },
      "outputs": [],
      "source": [
        "# Utilities to save the modelling results\n",
        "\n",
        "error_cols = [\"Model\", \"Train RMSE\", \"Train MAPE\", \"Test RMSE\", \"Test MAPE\"]\n",
        "error_table = pd.DataFrame(columns = error_cols)\n",
        "model_train_evaluation = dict()\n",
        "model_test_evaluation = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh7IH0k4eJ31"
      },
      "outputs": [],
      "source": [
        "# Function to save modelling results in a table\n",
        "\n",
        "def make_table(model_name, rmse_train, mape_train, rmse_test, mape_test):\n",
        "    global error_table\n",
        "    error_table = error_table.append(pd.DataFrame([[model_name, rmse_train, mape_train, rmse_test, mape_test]], columns = error_cols))\n",
        "    error_table.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW_gSguFtORX"
      },
      "outputs": [],
      "source": [
        "# Function to calulate RMSE and MAPE values\n",
        "\n",
        "def error_metrics(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = np.mean(abs((y_true - y_pred)/y_true))*100\n",
        "    return rmse, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihAwRgjMtVnv"
      },
      "outputs": [],
      "source": [
        "# Apply Xgboost Regressor on the Train and Test Data\n",
        "#XGBoost is a supervised machine learning method for classification and regression and is used by the Train Using AutoML tool.\n",
        "#XGBoost is short for extreme gradient boosting. This method is based on decision trees and improves on other methods such as random forest and gradient boost.\n",
        "#\n",
        "\n",
        "def train_test_xgboost(x_train, x_test, y_train, y_test, model_name):\n",
        "\n",
        "    startTime = datetime.now()\n",
        "    train_result = dict()\n",
        "    test_result = dict()\n",
        "\n",
        "    clf = xgb.XGBRegressor(n_estimators = 100, verbosity = 1, n_jobs  = 10)\n",
        "    # n_estimators is the number of trees in the ensemble,\n",
        "    # max_depth controls the depth of each tree (deeper trees capture more detail),\n",
        "    # learning_rate controls the contribution of each tree to the final prediction.\n",
        "    # n_jobs=10 means that the model will use up to 10 CPU cores if they’re available, which can significantly\n",
        "    # speed up the training process, especially for large datasets.\n",
        "\n",
        "    clf.fit(x_train, y_train)\n",
        "    #X (Features): This is the matrix of input features (e.g., user/movie averages, similar user ratings). Each row represents one data point (like a user-movie pair in your recommendation\n",
        "    # dataset), and each column is a feature.\n",
        "    # (Target/Label): This is the vector of target values you want the model to predict—in your case,\n",
        "    #the actual user-movie ratings. This tells the model what it’s supposed to learn in terms of output.\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"TRAIN DATA\")\n",
        "\n",
        "    y_pred_train = clf.predict(x_train)\n",
        "    #Predicts ratings for the training data to evaluate how well the model fits the training set\n",
        "\n",
        "    rmse_train, mape_train = error_metrics(y_train, y_pred_train)\n",
        "#y_train: This is the actual ratings vector for the training data, which contains the true ratings that users gave to movies in the dataset.\n",
        "#y_pred_train: This is the predicted ratings vector generated by the model for the training data. These are the model’s predictions\n",
        "#for what it \"thinks\" the ratings should be for each user-movie pair.\n",
        "\n",
        "    print(\"RMSE : {}\".format(rmse_train))\n",
        "    print(\"MAPE : {}\".format(mape_train))\n",
        "\n",
        "    train_result = {\"RMSE\": rmse_train, \"MAPE\": mape_train, \"Prediction\": y_pred_train}\n",
        "    #dictionary\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"TEST DATA\")\n",
        "\n",
        "    y_pred_test = clf.predict(x_test)\n",
        "    #akes predictions on the test dataset to evaluate model performance on unseen data.\n",
        "\n",
        "    rmse_test, mape_test = error_metrics(y_test, y_pred_test)\n",
        "    #Calculates RMSE and MAPE for test data\n",
        "\n",
        "    print(\"RMSE : {}\".format(rmse_test))\n",
        "    print(\"MAPE : {}\".format(mape_test))\n",
        "\n",
        "    test_result = {\"RMSE\": rmse_test, \"MAPE\": mape_test, \"Prediction\": y_pred_test}\n",
        "    #test_result is a dictionary that stores these values for RMSE< MAPE, predicitons\n",
        "\n",
        "    print(\"-\"*50)\n",
        "    print(\"Time Taken : \", datetime.now() - startTime)\n",
        "\n",
        "    plot_importance(xgb, clf)\n",
        "    #represents an instance of the XGBRegressor model from the xgboost library.\n",
        "\n",
        "    make_table(model_name, rmse_train, mape_train, rmse_test, mape_test)\n",
        "\n",
        "\n",
        "    return train_result, test_result\n",
        "\n",
        "# Function to plot feature importance for a model\n",
        "\n",
        "def plot_importance(model, clf):\n",
        "\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    fig = plt.figure(figsize = (25, 5))\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    #The dimensions (left, bottom, width, height) of the new Axes. All quantities are in fractions of figure width and height.\n",
        "\n",
        "    model.plot_importance(clf, ax = ax, height = 0.3)\n",
        "    #Uses XGBoost's built-in function to plot feature importance.\n",
        "    # clf: The trained XGBoost model.\n",
        "    # ax=ax: Specifies where to place the plot within the figure.\n",
        "    # height=0.3: Sets bar height in the plot.\n",
        "\n",
        "    plt.xlabel(\"F Score\", fontsize = 20)\n",
        "    plt.ylabel(\"Features\", fontsize = 20)\n",
        "    plt.title(\"Feature Importance\", fontsize = 20)\n",
        "    plt.tick_params(labelsize = 15)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRDoAkf-tV_j"
      },
      "outputs": [],
      "source": [
        "# in surprise prediction of every data point is returned as dictionary like this:\n",
        "#predictions is a list of prediction objects from Surprise, each containing keys like \"user\", \"item\", \"r_ui\" (the actual rating), and \"est\" (the estimated rating).\n",
        "# \"user: 196        item: 302        r_ui = 4.00   est = 4.06   {'actual_k': 40, 'was_impossible': False}\"\n",
        "# In this dictionary, \"r_ui\" is a key for actual rating and \"est\" is a key for predicted rating\n",
        "\n",
        "def get_ratings(predictions):\n",
        "    actual = np.array([pred.r_ui for pred in predictions])\n",
        "    #creates an array that contains the acutal ratings in the pred object of perdictions list\n",
        "\n",
        "    predicted = np.array([pred.est for pred in predictions])\n",
        "    #similar array for the estimated or predicted ratings values\n",
        "    return actual, predicted\n",
        "\n",
        "def get_error(predictions):\n",
        "    actual, predicted = get_ratings(predictions)\n",
        "    #calls the get_Ratings function to get the actual and predicted values lists.\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    mape = np.mean(abs((actual - predicted)/actual))*100\n",
        "    return rmse, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPvs450ttWF_"
      },
      "outputs": [],
      "source": [
        "my_seed = 15\n",
        "random.seed(my_seed)\n",
        "np.random.seed(my_seed)\n",
        "\n",
        "# Running Surprise model algorithms\n",
        "def run_surprise(algo, trainset, testset, model_name):\n",
        "  #The function will return two dictionaries (train and test),\n",
        "  #which will store evaluation metrics for the training and testing datasets.\n",
        "\n",
        "    startTime = datetime.now()\n",
        "\n",
        "    train = dict()\n",
        "    test = dict()\n",
        "\n",
        "    algo.fit(trainset)\n",
        "\n",
        "#-----------------Evaluating Train Data------------------#\n",
        "    print(\"-\"*50)\n",
        "    print(\"TRAIN DATA\")\n",
        "    train_pred = algo.test(trainset.build_testset())\n",
        "    #creates a test set from the training data, containing all user-item pairs for which ratings are available.\n",
        "    #algo.test() then evaluates these pairs, generating predictions for each.\n",
        "\n",
        "    train_actual, train_predicted = get_ratings(train_pred)\n",
        "#The function will return two lists: one for actual ratings and another for predicted ratings.\n",
        "\n",
        "    train_rmse, train_mape = get_error(train_pred)\n",
        "  #Tuple of two floats (float), representing RMSE and MAPE.\n",
        "\n",
        "    print(\"RMSE = {}\".format(train_rmse))\n",
        "    print(\"MAPE = {}\".format(train_mape))\n",
        "    train = {\"RMSE\": train_rmse, \"MAPE\": train_mape, \"Prediction\": train_predicted}\n",
        "\n",
        "#-----------------Evaluating Test Data------------------#\n",
        "    print(\"-\"*50)\n",
        "    print(\"TEST DATA\")\n",
        "    test_pred = algo.test(testset)\n",
        "    #algo.test()- generates the predictions for test_set\n",
        "\n",
        "    test_actual, test_predicted = get_ratings(test_pred)\n",
        "    #extract actual and predicted ratings.\n",
        "\n",
        "    test_rmse, test_mape = get_error(test_pred)\n",
        "    print(\"RMSE = {}\".format(test_rmse))\n",
        "    print(\"MAPE = {}\".format(test_mape))\n",
        "    test = {\"RMSE\": test_rmse, \"MAPE\": test_mape, \"Prediction\": test_predicted}\n",
        "\n",
        "    print(\"-\"*50)\n",
        "    print(\"Time Taken = \"+str(datetime.now() - startTime))\n",
        "\n",
        "    make_table(model_name, train_rmse, train_mape, test_rmse, test_mape)\n",
        "\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHtvOEiSxlJr"
      },
      "source": [
        "### **4.1 Train/test Splitting**\n",
        "\n",
        "We can split the data for train/test and segregate the independent and dependent features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4hVN2K5xPhg"
      },
      "outputs": [],
      "source": [
        "# Creating the train-test X and y variables for the ML algos\n",
        "\n",
        "x_train = train_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "#Here, x_train is created by removing (dropping) the columns User_ID, Movie_ID, and Rating from the train_regression_data DataFrame.\n",
        "#User_ID and Movie_ID are likely identifiers for the user and movie, which aren't useful as features for training a regression model, as they don’t provide information about the relationship between features and the rating outcome.\n",
        "#Rating is removed because it’s the target variable (or label) we are trying to predict, so it should be kept separate from the features. Including Rating as a feature would make the model \"cheat\" by already knowing the outcome.\n",
        "\n",
        "x_test = test_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "\n",
        "y_train = train_regression_data[\"Rating\"]\n",
        "y_test = test_regression_data[\"Rating\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHOzB0awyLbh"
      },
      "source": [
        "### **4.2 Model Fitting**\n",
        "\n",
        "Fitting various models and checking its accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9oMa_4pxdav"
      },
      "outputs": [],
      "source": [
        "# Training the Xgboost Regression Model on with the 13 features\n",
        "\n",
        "train_result, test_result = train_test_xgboost(x_train, x_test, y_train, y_test, \"XGBoost_13\")\n",
        "#train the xgboost regression model.\n",
        "model_train_evaluation[\"XGBoost_13\"] = train_result\n",
        "model_test_evaluation[\"XGBoost_13\"] = test_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck-ADocdz0Pf"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. \"User_Average\" by far seems to be the most important feature for rating prediction.\n",
        "2. \"Movie_Average\" is the second most important feature to predict the ratings.\n",
        "3. The top 5 Similar User ratings and top 5 Similar Movie Ratings doesn't seems to be the effective features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8aRMLGKxdjd"
      },
      "outputs": [],
      "source": [
        "# Applying BaselineOnly from the surprise library to predict the ratings\n",
        "# BaselineOnly model in Surprise calculates a predicted rating for a user-item pair by combining the global average rating with user and item biases.\n",
        "# The predicted rating for a user uu and item ii can be represented as:\n",
        "# prediction=global_mean+user_bias[u]+item_bias[i]\n",
        "# prediction=global_mean+user_bias[u]+item_bias[i]\n",
        "# This means that BaselineOnly doesn’t consider interactions between users and items beyond these biases\n",
        "\n",
        "bsl_options = {\"method\":\"sgd\", \"learning_rate\":0.01, \"n_epochs\":25}\n",
        "# #method: The method for optimization, set to \"sgd\", which stands for Stochastic Gradient Descent. This is the optimization algorithm used to minimize the error during training.\n",
        "# learning_rate: The step size for the SGD optimizer, set to 0.01. This controls how much thewhat model adjusts its parameters with each step.\n",
        "# n_epochs: The number of training epochs, set to 25. This determines how many times the model iterates over the data to refine the baseline estimates.\n",
        "\n",
        "algo = BaselineOnly(bsl_options=bsl_options)\n",
        "#BaselineOnly algorithm from the Surprise library with the specified bsl_options.\n",
        "#BaselineOnly is a simple algorithm that predicts ratings based on baseline estimates (such as user and item biases).\n",
        "#Purpose: BaselineOnly is used to generate baseline predictions by adjusting for the general tendency of each user (e.g., some users give consistently higher\n",
        "#or lower ratings) and each item (e.g., some items are generally rated higher).\n",
        "\n",
        "train_result, test_result = run_surprise(algo, trainset, testset, \"BaselineOnly\")\n",
        "# #algo: The BaselineOnly model initialized with specified hyperparameters.\n",
        "# trainset: The training dataset, typically a surprise.Trainset object.\n",
        "# testset: The test dataset, containing unseen data to evaluate the model.\n",
        "# \"BaselineOnly\": This string argument may be used to label the model within the run_surprise function\n",
        "\n",
        "model_train_evaluation[\"BaselineOnly\"] = train_result\n",
        "model_test_evaluation[\"BaselineOnly\"] = test_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWo35mUvxdrG"
      },
      "outputs": [],
      "source": [
        "# Adding predicted ratings from Surprise BaselineOnly model to our Train and Test Dataframe\n",
        "\n",
        "train_regression_data[\"BaselineOnly\"] = model_train_evaluation[\"BaselineOnly\"][\"Prediction\"]\n",
        "#creates a new column  \"baselineonly\" -\n",
        "#This accesses the list of predicted ratings from model_train_evaluation.\n",
        "#model_train_evaluation[\"BaselineOnly\"][\"Prediction\"]: This accesses the list of predicted ratings from model_train_evaluation.\n",
        "test_regression_data[\"BaselineOnly\"] = model_test_evaluation[\"BaselineOnly\"][\"Prediction\"]\n",
        "\n",
        "#model train evaluation is a dictionary of dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u97Z1mevPEWC"
      },
      "outputs": [],
      "source": [
        "train_regression_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOWZ4lCEPhmK"
      },
      "outputs": [],
      "source": [
        "test_regression_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xkzVWl4PiMI"
      },
      "outputs": [],
      "source": [
        "# Fitting the Xgboost again with new BaselineOnly feature\n",
        "\n",
        "x_train = train_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "x_test = test_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "\n",
        "y_train = train_regression_data[\"Rating\"]\n",
        "y_test = test_regression_data[\"Rating\"]\n",
        "\n",
        "train_result, test_result = train_test_xgboost(x_train, x_test, y_train, y_test, \"XGB_BSL\")\n",
        "\n",
        "model_train_evaluation[\"XGB_BSL\"] = train_result\n",
        "#a dictionary that stores the value of the algorithm's evaluation metrics, given by the train_result dictionary(rmse, mape, predictions)\n",
        "model_test_evaluation[\"XGB_BSL\"] = test_result\n",
        "\n",
        "#BaselineOnly predictions as a feature in x_train and x_test, you provide the XGBoost model with more information that captures general rating trends. This gives XGBoost a foundation of baseline predictions\n",
        "#from which it can learn further, capturing additional complexity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWu3LQlS2t8V"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The \"BaselineOnly\" feature is also not an important feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR81n3RDPiUi"
      },
      "outputs": [],
      "source": [
        "# Finding the suitable parameter for Surprise KNN-Baseline with User-User Similarity\n",
        "\n",
        "param_grid  = {'sim_options':{'name': [\"pearson_baseline\"], \"user_based\": [True], \"min_support\": [2], \"shrinkage\": [60, 80, 80, 140]}, 'k': [5, 20, 40, 80]}\n",
        "#uses pearson correlation  (baseline)\n",
        "#user-user based similarity matrix corresponding to collaborative filtering: wherein we're trying to find similarity between two users based on the items they rate (similar preferences)\n",
        "# Sets the minimum number of common ratings required to compute similarity between two users. A value of 2 is specified here to ensure that at least two common items exist.\n",
        "# values of shrinkage coefficients to regularise in case of overfitting\n",
        "# number of nearest neighbors (k-NN) to consider in the model. The grid search will test different values (5, 20, 40, 80) to find the best-performing one.\n",
        "\n",
        "gs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "#GRIDSEARCHCV is a method to tune hyperparameters by testing all parameters in a predefined set (parameter grid). Each model variation is then cross-validated. the models are evaluated using\n",
        "#a specified evaluation metric. (RMSE, MAPE)\n",
        "#After running all combinations, GridSearchCV provides the best parameter set (best_params_), the best score (best_score_), and the model trained on that best parameter set (best_estimator_).\n",
        "\n",
        "#1) model to be run\n",
        "#2) contains the hyperparameters to search through (given above)\n",
        "#3) cv=3,  specifying 3-fold cross-validation for each parameter combination.\n",
        "#The dataset D is split into three equally sized subsets. The fitting and evaluation procedure of the model is repeated three times,\n",
        "#with a different subset serving as training sample each time. The performances of the three test sets are aggregated to a final score.\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s413sLXYXQ3K"
      },
      "outputs": [],
      "source": [
        "# Applying the KNN-Baseline with the searched parameters\n",
        "#performing a grid search to find the best parameters for the KNN-Baseline model in the Surprise library, specifically with user-user similarity settings\n",
        "#similarity matrix produced by the model will use the Pearson baseline method and return similarity scores as float values for each user-user pair\n",
        "\n",
        "sim_options = {'name':'pearson_baseline', 'user_based':True, 'min_support':2, 'shrinkage':gs.best_params['rmse']['sim_options']['shrinkage']}\n",
        "#1)pearson_baseline\" as the similarity metric, which is a variation of Pearson correlation adjusted to reduce noise.\n",
        "#2)User-user similarity : user-user collaborative filtering. This approach is often preferred when recommending items based on similar user preferences rather than item-item characteristics.\n",
        "#3)Sets the minimum number of common ratings required to compute similarity between two users. A value of 2 is specified here to ensure that at least two common items exist.\n",
        "#ng min_support=2 helps reduce noise by ensuring that similarity calculations are only made when there’s a reasonable amount of data to base the similarity score on.\n",
        "#4)shrinkage: shrinkage regularizes similarity scores to avoid overestimating the similarity between users who have only rated a few items in common. This adjustment reduces the impact of users who might coincidentally\n",
        "# rate a few items the same but aren’t truly similar in their broader preferences.\n",
        "# Different values of shrinkage are tested to see which degree of regularization provides the best results.\n",
        "# Lower shrinkage (e.g., 60) means the similarity scores are closer to their original values, while higher shrinkage (e.g., 140) smooths them more, reducing the impact of a few co-rated items.\n",
        "# Finding the optimal shrinkage helps balance between relying on co-rated items and mitigating any outliers or noise.\n",
        "# (gs.best_params['rmse']) return a dictionary that includes the optimal values for each parameter (e.g., \"shrinkage\": 80, \"k\": 40).\n",
        "# GridSearch is a method to tune the hyperparameters\n",
        "\n",
        "bsl_options = {'method': 'sgd'}\n",
        "#Using method: 'sgd' means the model will adjust these biases iteratively through SGD, often leading to better performance.\n",
        "#stochastic gradient descent\n",
        "\n",
        "algo = KNNBaseline(k = gs.best_params['rmse']['k'], sim_options = sim_options, bsl_options=bsl_options)\n",
        "#algorithm = KNN_Baseline;\n",
        "\n",
        "train_result, test_result = run_surprise(algo, trainset, testset, \"KNNBaseline_User\")\n",
        "#store the train and test results, using the run_surprise method.\n",
        "\n",
        "model_train_evaluation[\"KNNBaseline_User\"] = train_result\n",
        "#dictionary stores the dictionary for KNN BASELINE METRIC EVALUATION.\n",
        "model_test_evaluation[\"KNNBaseline_User\"] = test_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnvfcx_IP8Nb"
      },
      "outputs": [],
      "source": [
        "# Similarly finding best parameters for Surprise KNN-Baseline with Item-Item Similarity\n",
        "#If the dataset has a high number of users but each user rates only a small subset of items, it can be challenging to find enough meaningful user-user similarities. In such cases, item-item similarity often works better because the same items tend to get rated by many users, providing a stronger basis for similarity.\n",
        "#By calculating item-item similarities, you can still make effective recommendations even if individual users have rated only a few items.\n",
        "\n",
        "param_grid  = {'sim_options':{'name': [\"pearson_baseline\"], \"user_based\": [False], \"min_support\": [2], \"shrinkage\": [60, 80, 80, 140]}, 'k': [5, 20, 40, 80]}\n",
        "# we've set the user-based to FALSE: to create an item-item based similarity matrix\n",
        "\n",
        "gs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "#create a grid_search cv object, for knn basline, with the same parameter_grid, with 3 cv sets, and the same measures as before.\n",
        "\n",
        "gs.fit(data)\n",
        "#fit the data\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7Z9aOmVe_xJ"
      },
      "outputs": [],
      "source": [
        "# Applying KNN-Baseline with best parameters searched\n",
        "\n",
        "sim_options = {'name':'pearson_baseline', 'user_based':False, 'min_support':2, 'shrinkage':gs.best_params['rmse']['sim_options']['shrinkage']}\n",
        "#First Approach (User-User Similarity): In the first setup, you were performing grid search and evaluation using user-user similarity for the KNNBaseline model.\n",
        "#Second Approach (Item-Item Similarity): Here, you are applying item-item similarity for the same KNNBaseline model, but with a different set of parameters that are optimized for item-item collaborative filtering.\n",
        "\n",
        "bsl_options = {'method': 'sgd'}\n",
        "#stochastic gradient method\n",
        "\n",
        "algo = KNNBaseline(k = gs.best_params['rmse']['k'], sim_options = sim_options, bsl_options=bsl_options)\n",
        "#algorithm = knnbaseline, with the value of k as obtained(optimal) from the gs.bestparam[rmse](dictionary)'s value for K\n",
        "\n",
        "train_result, test_result = run_surprise(algo, trainset, testset, \"KNNBaseline_Item\")\n",
        "#run the algo on the train and test set and find the results stored in teh trainresult and test result dictionaries.\n",
        "\n",
        "model_train_evaluation[\"KNNBaseline_Item\"] = train_result\n",
        "#put the disctionary(train_result) inside the dictionary with key KNN BASELINE_ITEM\n",
        "model_test_evaluation[\"KNNBaseline_Item\"] = test_result\n",
        "#similarylt for test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsaBV9Dee_4W"
      },
      "outputs": [],
      "source": [
        "# Addding the KNNBaseline features to the train and test dataset\n",
        "\n",
        "train_regression_data[\"KNNBaseline_User\"] = model_train_evaluation[\"KNNBaseline_User\"][\"Prediction\"]\n",
        "train_regression_data[\"KNNBaseline_Item\"] = model_train_evaluation[\"KNNBaseline_Item\"][\"Prediction\"]\n",
        "#The code assigns predictions made by a KNN-based baseline model for both \"User\" and \"Item\" to train_regression_data.\n",
        "\n",
        "test_regression_data[\"KNNBaseline_User\"] = model_test_evaluation[\"KNNBaseline_User\"][\"Prediction\"]\n",
        "test_regression_data[\"KNNBaseline_Item\"] = model_test_evaluation[\"KNNBaseline_Item\"][\"Prediction\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXyEnuqyP8ZT"
      },
      "outputs": [],
      "source": [
        "train_regression_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLiU_CQZi54v"
      },
      "outputs": [],
      "source": [
        "test_regression_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHXSFZKMi6AP"
      },
      "outputs": [],
      "source": [
        "# Applying Xgboost with the KNN-Baseline newly added features\n",
        "\n",
        "x_train = train_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "x_test = test_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "\n",
        "y_train = train_regression_data[\"Rating\"]\n",
        "y_test = test_regression_data[\"Rating\"]\n",
        "\n",
        "train_result, test_result = train_test_xgboost(x_train, x_test, y_train, y_test, \"XGB_BSL_KNN\")\n",
        "\n",
        "model_train_evaluation[\"XGB_BSL_KNN\"] = train_result\n",
        "model_test_evaluation[\"XGB_BSL_KNN\"] = test_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXq9kbgY3U4d"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. The KNN Baseline features are also not an effective predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBr_3oOavecn"
      },
      "outputs": [],
      "source": [
        "# Appling the SlopeOne algorithm from the Surprise library\n",
        "\n",
        "so = SlopeOne()\n",
        "\n",
        "train_result, test_result = run_surprise(so, trainset, testset, \"SlopeOne\")\n",
        "#store the evaluation results in model_train_evaluation and model_test_evaluation dictionaries\n",
        "model_train_evaluation[\"SlopeOne\"] = train_result\n",
        "model_test_evaluation[\"SlopeOne\"] = test_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txZf2PxLzMBV"
      },
      "outputs": [],
      "source": [
        "# Adding the SlopOne predictions to the train and test datasets\n",
        "\n",
        "train_regression_data[\"SlopeOne\"] = model_train_evaluation[\"SlopeOne\"][\"Prediction\"]\n",
        "train_regression_data[\"SlopeOne\"] = model_train_evaluation[\"SlopeOne\"][\"Prediction\"]\n",
        "\n",
        "test_regression_data[\"SlopeOne\"] = model_test_evaluation[\"SlopeOne\"][\"Prediction\"]\n",
        "test_regression_data[\"SlopeOne\"] = model_test_evaluation[\"SlopeOne\"][\"Prediction\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyAlM4pNjsQa"
      },
      "outputs": [],
      "source": [
        "# Matrix Factorization using SVD from Surprise Library\n",
        "\n",
        "# here, n_factors is the equivalent to dimension 'd' when matrix 'A'\n",
        "# is broken into 'b' and 'c'. So, matrix 'A' will be of dimension n*m. So, matrices 'b' and 'c' will be of dimension n*d and m*d.\n",
        "param_grid  = {'n_factors': [5,7,10,15,20,25,35,50,70,90]}\n",
        "#n_factors is the number of latent factors we’re trying to find the best value for.\n",
        "# If n_factors is too small, the model might miss important patterns (e.g., it may not capture all movie genres or user preferences).\n",
        "# If n_factors is too large, the model may \"overfit,\" learning noise instead of real preferences, which could reduce its generalization to new data.\n",
        "# If A has dimensions n×mn×m, the factor matrices b and c will be of size n×dn×d and m×dm×d, where d = n_factors\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "#SVD is the algorithm used to perform matrix factorization.\n",
        "# GridSearchCV tests each value of n_factors in param_grid to see which number of latent factors results in the most accurate predictions.\n",
        "# It does this by measuring the RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error) across three different cross-validation splits (i.e., cv=3).\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n recommendation systems, matrix factorization is a technique that breaks down a large matrix (like a user-item rating matrix) into smaller matrices. This helps reveal hidden patterns or \"latent factors\" that explain users' preferences and items' characteristics.\n",
        "\n",
        "For example:\n",
        "\n",
        "    Suppose you have a matrix AA representing user ratings, with dimensions n×mn×m, where nn is the number of users and mm is the number of items.\n",
        "    Matrix factorization breaks down AA into two matrices, BB and CC, where:\n",
        "        BB has dimensions n×dn×d\n",
        "        CC has dimensions m×dm×d\n",
        "        dd is the number of latent factors and is controlled by the parameter n_factors in the Surprise SVD model.\n",
        "\n",
        "The goal is to choose n_factors so that BB and CC can reconstruct AA as accurately as possible. In recommendation systems, each latent factor can represent an underlying feature of user or item preferences, such as genre preference for movies or age-related preferences."
      ],
      "metadata": {
        "id": "2P5YCdTKEP8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcDl9ohMjsby"
      },
      "outputs": [],
      "source": [
        "# Applying SVD with best parameters\n",
        "\n",
        "algo = SVD(n_factors = gs.best_params['rmse']['n_factors'], biased=True, verbose=True)\n",
        "\n",
        "train_result, test_result = run_surprise(algo, trainset, testset, \"SVD\")\n",
        "#stores the value of the train and test result in the dcitioantires\n",
        "\n",
        "model_train_evaluation[\"SVD\"] = train_result\n",
        "#sotre that dictionary in the corresponding algorithm's dictionary.\n",
        "model_test_evaluation[\"SVD\"] = test_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFHZWzsIjsj6"
      },
      "outputs": [],
      "source": [
        "# Matrix Factorization SVDpp with implicit feedback\n",
        "\n",
        "# Hyper-parameter optimization for SVDpp\n",
        "param_grid = {'n_factors': [10, 30, 50, 80, 100], 'lr_all': [0.002, 0.006, 0.018, 0.054, 0.10]}\n",
        "# Controls the number of latent factors used to represent users and items. This is part of the core matrix factorization process, where higher values can capture more complex patterns but might lead to overfitting.\n",
        "#his is the learning rate for the model. It controls how quickly the model learns by adjusting factors based on the error in each iteration.\n",
        "# A lower learning rate (e.g., 0.002) can lead to slower, more stable convergence, while a higher rate (e.g., 0.10) may lead to faster but potentially unstable training.\n",
        "\n",
        "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "# we re usign the SVDpp, with parameterr grid defined earlier, and the measures being rmse, and mae, with Cross validation of 3\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXFYvjDSNrot"
      },
      "outputs": [],
      "source": [
        "#Applying SVDpp with best parameters¶\n",
        "\n",
        "algo = SVDpp(n_factors = gs.best_params['rmse']['n_factors'], lr_all = gs.best_params['rmse'][\"lr_all\"], verbose=True)\n",
        "\n",
        "train_result, test_result = run_surprise(algo, trainset, testset, \"SVDpp\")\n",
        "\n",
        "model_train_evaluation[\"SVDpp\"] = train_result\n",
        "model_test_evaluation[\"SVDpp\"] = test_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF9iguN0Nr4K"
      },
      "outputs": [],
      "source": [
        "# XGBoost 13 Features + Surprise BaselineOnly + Surprise KNN Baseline + SVD + SVDpp\n",
        "\n",
        "train_regression_data[\"SVD\"] = model_train_evaluation[\"SVD\"][\"Prediction\"]\n",
        "train_regression_data[\"SVDpp\"] = model_train_evaluation[\"SVDpp\"][\"Prediction\"]\n",
        "\n",
        "test_regression_data[\"SVD\"] = model_test_evaluation[\"SVD\"][\"Prediction\"]\n",
        "test_regression_data[\"SVDpp\"] = model_test_evaluation[\"SVDpp\"][\"Prediction\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEcSXYUPOAHK"
      },
      "outputs": [],
      "source": [
        "train_regression_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaRt6dx3OAPr"
      },
      "outputs": [],
      "source": [
        "test_regression_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIzbKpBCOZPj"
      },
      "outputs": [],
      "source": [
        "# Applying Xgboost on the feature set\n",
        "\n",
        "x_train = train_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "x_test = test_regression_data.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n",
        "\n",
        "y_train = train_regression_data[\"Rating\"]\n",
        "y_test = test_regression_data[\"Rating\"]\n",
        "\n",
        "train_result, test_result = train_test_xgboost(x_train, x_test, y_train, y_test, \"XGB_BSL_KNN_MF\")\n",
        "\n",
        "model_train_evaluation[\"XGB_BSL_KNN_MF\"] = train_result\n",
        "model_test_evaluation[\"XGB_BSL_KNN_MF\"] = test_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM5nqCQO7-bP"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. SVD did better than KNNBaseline features but SVDpp turned out to be the most ineffective predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKxWh4MLOkwS"
      },
      "outputs": [],
      "source": [
        "# Applying Xgboost with Surprise's BaselineOnly + KNN Baseline + SVD + SVDpp + SlopeOne\n",
        "\n",
        "x_train = train_regression_data[[\"BaselineOnly\", \"KNNBaseline_User\", \"KNNBaseline_Item\", \"SVD\", \"SVDpp\", \"SlopeOne\"]]\n",
        "x_test = test_regression_data[[\"BaselineOnly\", \"KNNBaseline_User\", \"KNNBaseline_Item\", \"SVD\", \"SVDpp\", \"SlopeOne\"]]\n",
        "\n",
        "y_train = train_regression_data[\"Rating\"]\n",
        "y_test = test_regression_data[\"Rating\"]\n",
        "\n",
        "train_result, test_result = train_test_xgboost(x_train, x_test, y_train, y_test, \"XGB_KNN_MF_SO\")\n",
        "\n",
        "model_train_evaluation[\"XGB_KNN_MF_SO\"] = train_result\n",
        "model_test_evaluation[\"XGB_KNN_MF_SO\"] = test_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HokRtRNcEwLj"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. SVD seems to be the best estimator of the rating predictions.\n",
        "2. SVDpp and Baseline Only also seems to be a important feature.\n",
        "3. SlopeOne, KNNBaseline features are also decent estimators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne4zXGtyOk87"
      },
      "outputs": [],
      "source": [
        "# Visualizing the errors of all the models we tested out\n",
        "\n",
        "error_table2 = error_table.drop([\"Train MAPE\", \"Test MAPE\"], axis = 1)\n",
        "error_table2.plot(x = \"Model\", kind = \"bar\", figsize = (25, 8), grid = True, fontsize = 15)\n",
        "plt.title(\"Train and Test RMSE and MAPE of all Models\", fontsize = 20)\n",
        "#Bar Plot (kind=\"bar\"): A bar plot is suitable here as it allows easy comparison of error values (e.g., RMSE) across different models.\n",
        "# x-axis and(x=\"Model\"): This sets the Model column as the x-axis, so each bar represents a different model.\n",
        "# Figure Size (figsize=(25, 8)): The plot is set to be large, making it easier to read each model’s error values, especially if there are many models.\n",
        "plt.ylabel(\"Error Values\", fontsize = 10)\n",
        "plt.xticks(rotation=60)\n",
        "plt.legend(bbox_to_anchor=(1, 1), fontsize = 10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Cw8QDCPY8Qj"
      },
      "outputs": [],
      "source": [
        "# Tabular Values of Errors\n",
        "\n",
        "error_table.drop([\"Train MAPE\", \"Test MAPE\"], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1isisrvFM9S"
      },
      "source": [
        "Observations:\n",
        "1. All the algorithms seems to do great with the differences remaining very close to each other.\n",
        "\n",
        "2. We can see that by using various rating predicting algorithms together and stacking them up, then using final algorithms seems to result in lowest Testing RMSE. Eg: Surprise's BaselineOnly + KNN Baseline + SVD + SVDpp + SlopeOne together with Xgboost.\n",
        "\n",
        "3. SlopeOne seems to have lowest Testing RMSE out of all other algorithms.\n",
        "\n",
        "4. SVDpp and SVD are algorithms showing lower Testing RMSE among rest of the predictors except SlopeOne.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkOkaTE7cP8b"
      },
      "source": [
        "### **4.3 Generating Recommendation for Users**\n",
        "\n",
        "We are using SVDpp to generate atmost 10 recommendated movies for various users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qknLs2XXGpHg"
      },
      "outputs": [],
      "source": [
        "# Testing the recommendations made by SVDpp Algorithm\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def Get_top_n(predictions, n=10):\n",
        "  #get top 10 predictions made using the algorithm\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        " #defaultdict is similar to a regular dictionary but with a default value for missing keys. In this case,\n",
        " #it will automatically initialize an empty list for each new user ID.\n",
        "\n",
        "    for uid, mid, true_r, est, _ in predictions:\n",
        "#uid: User ID.\n",
        "# mid: Movie ID.\n",
        "# true_r: The actual rating given by the user (optional or unavailable in testing scenarios).\n",
        "# est: The predicted rating for the movie (generated by the algorithm).\n",
        "# _: Any additional metadata (not used in this function).\n",
        "\n",
        "        top_n[uid].append((mid, est))\n",
        "        #group predictions for each user(uid as key, the mid, est as values)\n",
        "        #For each prediction, it appends a tuple (mid, est) to the list of recommendations\n",
        "        #for the corresponding user ID (uid) in the top_n dictionary.\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "    #Sorts the list of movies for each user (user_ratings) in descending order based on their predicted ratings (est).\n",
        "    # The key=lambda x: x[1] specifies that the second element in each tuple (est) is used for sorting.\n",
        "\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "        #slices the list to:-\n",
        "        #add the user ratings for that uid (only the top n)\n",
        "\n",
        "    return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD6WGG-VGpc5"
      },
      "outputs": [],
      "source": [
        "# Creating instance of svd_pp\n",
        "\n",
        "svd_pp = SVDpp(n_factors = 10, lr_all = 0.006, verbose=True)\n",
        "#n_factors=10:\n",
        "\n",
        "# The number of latent factors for users and items.\n",
        "# Latent factors represent hidden features of users and items (e.g., genre preference for users, genres for movies).\n",
        "# A lower number like 10 makes the model simpler and faster, while a higher number captures more details at the cost of complexity.\n",
        "# lr_all=0.006:\n",
        "# The learning rate for all parameters.\n",
        "# Controls how much the model updates its weights during training. A lower value like 0.006 ensures slower but more stable learning.\n",
        "#verbose=True:\n",
        "#Enables printing of progress messages during training, which is helpful for debugging or monitoring.\n",
        "\n",
        "svd_pp.fit(trainset)\n",
        "#fit the algorithm on the training set.\n",
        "\n",
        "predictions = svd_pp.test(testset)\n",
        "#predictions: A list of Prediction objects, where each object contains:\n",
        "    # uid: User ID.\n",
        "    # iid: Item ID.\n",
        "    # true_r: The true rating.\n",
        "    # est: The estimated rating (predicted by the algorithm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcxJG6u9K8Jp"
      },
      "outputs": [],
      "source": [
        "# Saving the training predictions (data for which ratings havent been made)\n",
        "\n",
        "train_pred = svd_pp.test(trainset.build_anti_testset())\n",
        "# #This generates the anti-test set for the training set.\n",
        "# An anti-test set includes all (user, item) pairs where the user has not rated the item in the training set.\n",
        "# It's used to simulate predictions for unrated items, which are potential recommendations\n",
        "\n",
        "#svd_pp.test():\n",
        "#The test() method is called to predict ratings for the anti-test set using the trained svd_pp model.\n",
        "#It produces a list of Prediction objects for all these (user, item) pairs.\n",
        "\n",
        "top_n = Get_top_n(train_pred, n=10)\n",
        "#the method returns the top 10 predicitons made on the train_pred (set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyatTqwuU8f7"
      },
      "outputs": [],
      "source": [
        "# Print the recommended items for each user\n",
        "\n",
        "def Generate_Recommendated_Movies(u_id, n=10):\n",
        "\n",
        "    recommend = pd.DataFrame(top_n[u_id], columns=[\"Movie_Id\", \"Predicted_Rating\"])\n",
        "    #The dictionary top_n, which contains top recommendations for all users.\n",
        "#     top_n[u_id]: Returns a list of tuples for the specified user ID, where each tuple contains:\n",
        "#         Movie_Id: The recommended movie ID.\n",
        "#         Predicted_Rating: The estimated rating for that movie.\n",
        "# Output: A DataFrame recommend with two columns:\n",
        "#     Movie_Id: The recommended movie IDs.\n",
        "#     Predicted_Rating: Predicted ratings for those movies\n",
        "\n",
        "    recommend = recommend.merge(movies, how=\"inner\", left_on=\"Movie_Id\", right_on=\"movieId\")\n",
        "    #performs an inner join on recommend and movies, for the columns movie id on recommend and the oterh on the movies dataframe.\n",
        "    #essentially, what it does is, it Adds the movie details (title and genres) to the recommendations.\n",
        "\n",
        "    recommend = recommend[[\"Movie_Id\", \"title\", \"genres\", \"Predicted_Rating\"]]\n",
        "    #we re only gonna keep these columns on the recommend dataframe.\n",
        "\n",
        "    return recommend[:n]\n",
        "    #get the top n values frmo the recommend data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf6Akdw7g8ZJ"
      },
      "outputs": [],
      "source": [
        "# Saving the sampled user id list to help generate movies\n",
        "\n",
        "sampled_user_id = list(top_n.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gv7rfB6gh2d"
      },
      "outputs": [],
      "source": [
        "# Generating recommendation using the user_Id\n",
        "\n",
        "test_id = random.choice(sampled_user_id)\n",
        "#generate a random user id\n",
        "print(\"The user Id is : \", test_id)\n",
        "Generate_Recommendated_Movies(test_id)\n",
        "#generate the recommended movies for that test_id(user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRb8a49Id6kh"
      },
      "outputs": [],
      "source": [
        "# Generating recommendation using the user_Id\n",
        "\n",
        "test_id = random.choice(sampled_user_id)\n",
        "print(\"The user Id is : \", test_id)\n",
        "Generate_Recommendated_Movies(test_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51RB8NiSUQLc"
      },
      "outputs": [],
      "source": [
        "# Generating recommendation using the user_Id\n",
        "\n",
        "test_id = random.choice(sampled_user_id)\n",
        "print(\"The user Id is : \", test_id)\n",
        "Generate_Recommendated_Movies(test_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxildI7PddW1"
      },
      "outputs": [],
      "source": [
        "# Generating recommendation using the user_Id\n",
        "\n",
        "test_id = random.choice(sampled_user_id)\n",
        "print(\"The user Id is : \", test_id)\n",
        "Generate_Recommendated_Movies(test_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHCPDN8TGnDs"
      },
      "source": [
        "## **5. Conclusion**\n",
        "\n",
        "In this project, we learned the importance of Recommendation Systems, the types of recommender systems being implemented, and how to use matrix factorization to enhance a system.\n",
        "\n",
        "We then built a movie recommendation system that considers user-user similarity, movie-movie similarity, global averages and matrix factorization. These concepts can be applied to any other user-item interactions systems.\n",
        "\n",
        "We tried generating recommendations based on similarity matrix and Collaborative Filtering techniques.\n",
        "\n",
        "We tried to predict the ratings for movies that the user might give based on its past rating behaviours and measure the accuracy using RMSE and MAPE error metrics.\n",
        "\n",
        "Surely, there is huge scope of improvement and tring out different techniques and ML/DL algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rATzAMteJ7T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1pXuBHOOoEpp",
        "rU01nw0IG9wP",
        "93fagKfprG8u",
        "LHtvOEiSxlJr",
        "FkOkaTE7cP8b"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}